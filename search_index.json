[
["index.html", "R para jurimetria Capítulo 1 Apresentação", " R para jurimetria Associação Brasileira de Jurimetria 24 de January de 2018 Capítulo 1 Apresentação Olá! Bem vindo ao curso R para Jurimetria :) Essa é a primeira iteração do curso de R para Jurimetria da ABJ. Nesse curso abordamos aspectos práticos da Jurimetria, essenciais para um profissional da Estatística que tenha interesse em trabalhar nessa área. O curso é voltado para graduandos em estatística e está organizado em cinco aulas. (15/01) Introdução à jurimetria e setup Definição Terminologia Tipos de pesquisa e exemplos Ambientação com R e RStudio RMarkdown (17/01) Ferramentas da ABJ para importação Introdução ao web scraping com httr e rvest. Pacotes abjutils, esaj e dje. (19/01) Tidyverse: vetores Vetores: pacotes stringr, lubridate, forcats. Programação funcional: purrr. (22/01) Tidyverse: bd Transformação: pacotes dplyr, tidyr. Aplicação: Câmaras criminais. (24/01) Modelagem Especialização de varas: pacotes bnlearn e survival. Captchas: pacotes keras e decryptr. Para o curso, será necessário ter conhecimentos do software estatístico R, como a lógica de programação, sintaxe do R e ambientação com o RStudio. "],
["introducao.html", "Capítulo 2 Introdução", " Capítulo 2 Introdução Bem vinda ao maravilhoso mundo da jurimetria. Essa é sua última chance. Está preparada? "],
["o-que-e-jurimetria.html", "2.1 O que é Jurimetria?", " 2.1 O que é Jurimetria? A jurimetria é o estudo empírico do direito. Ela se distingue das demais disciplinas jurídicas por tratar o direito de forma concreta. A pesquisa em jurimetria utiliza dados do judiciário para avaliar desde argumentos quantitativos a serem utilizados por juristas e advogados até o impacto de leis. No Brasil, é utilizada principalmente como ferramenta para auxiliar na formulação de políticas públicas, melhorar a administração dos tribunais, calcular o risco de carteiras de processos e otimizar estratégias processuais. A jurimetria está para o Direito da mesma forma que a econometria, a biometria e a sociometria estão, respectivamente, para a Economia, Biologia e Sociologia. O Direito, embora conte com algumas áreas tradicionalmente mais empíricas que outras, ainda não tem uma disciplina mais formalizada. No mundo corporativo, a jurimetria está se tornando essencial para departamentos jurídicos de grandes empresas e escritórios de advocacia. O movimento da tecnologia no Direito ganhou ainda mais força no ano de 2017 com o advento da AB2L e das lawtechs, as startups do meio jurídico. Nesse sentido, uma das missões da Associação Brasileira de Jurimetria (ABJ) é incentivar e divulgar a jurimetria aos seus associados e ao público em geral. Nossos estudos e pesquisas visam a difusão e o desenvolvimento do campo no Brasil, agregando pesquisadores e fornecendo o ferramental necessário para realização das análises. Neste curso, apresentaremos o ferramental de trabalho desenvolvido no laboratório da ABJ. As ferramentas servem principalmente para extração e arrumação de dados, deixando o caminho livre para realização de análises estatísticas mais aprofundadas. "],
["tipos-de-estudo.html", "2.2 Tipos de estudo", " 2.2 Tipos de estudo No decorrer do curso trabalharemos dois tipos comuns de estudos jurimétricos: prospectivo e retrospectivo. É importante separar esses tipos de estudo tanto pela matéria desenvolvida quanto pelas fontes de dados disponíveis. Faremos isso através de um exemplo. 2.2.1 Exemplo Digamos que a NET tenha colocado seu nome indevidamente no Serasa e você processa ela. Quando você entra com um processo, ele é distribuído (levado) numa vara (casinha do juiz), por exemplo uma vara cível de São Carlos, e seu processo estará na 1a instância. O juiz então irá decidir sobre o caso, produzindo uma sentença (um texto de 5-10 páginas que explica o que ele decidiu e por quê). Se você ou a NET ficarem infelizes com o resultado, vocês podem entrar com um recurso de apelação (evolução de processo), que será distribuído numa câmara (evolução de vara) do Tribunal de Justiça de São Paulo (TJSP, que fica na praça da Sé, em São Paulo), a ser julgada por desembargadores (evolução de juiz), e seu processo estará na 2a instância. Os desembargadores então irão decidir sobre o caso, produzindo um acórdão (evolução de sentença). Se você ou a NET ficarem infelizes com o resultado, vocês podem novamente entrar com recursos, que irão para o STJ e posteriormente ao STF (em Brasília), a serem julgados por Ministros (evolução de desembargador). Nossos estudos restringem-se ao TJSP, envolvendo (1) e (2). O TJSP atualmente é o mais simples para obtenção automática de processos. 2.2.2 Divisão regional O TJSP é dividido em comarcas, circunscrições e regiões administrativas. As comarcas são conjuntos de um ou mais municípios e uma comarca deve sempre ter uma ou mais varas. Circunscrições e regiões administrativas existem somente para 2.2.3 Qual tipo escolher? Estudo prospectivo é o estudo que acompanha o processo judicial desde a data de distribuição até o fim. O fim pode ser marcado pela data da sentença, acórdão, ou outro evento de interesse. Ou seja, os casos são indexados pela data de nascimento, e acompanhados até a data de sua morte. Em muitos casos, os processos ainda não atingiram o fim no momento da realização do estudo. Estudo retrospectivo é o estudo que levanta processos que acabaram (por sentença ou por acórdão) e analisa suas características. Ou seja, os casos são indexados pela data de morte. A Figura abaixo mostra os diferentes escopos. ( 1) Prospectivo e retrospectivo. ( 2) Apenas prospectivo. ( 3) Apenas retrospectivo. ( 4) Nenhum dos dois, mas poderia ser capturado por atividade no período. (5 e 6) fora do escopo. ( 7) Nenhum dos dois tipos e não poderia ser capturado (ficou inativo no período). Estudos prospectivos são úteis quando o intuito é estudar o tempo das fases do processo. Já estudos retrospectivos são úteis para a análise do perfil de decisões. Estudos que analisam tempos em bases retrospectivas. Se quiser saber mais sobre isso, veja esse texto. "],
["estudo-1-camaras-criminais.html", "2.3 Estudo 1: Câmaras criminais", " 2.3 Estudo 1: Câmaras criminais O Direito Criminal é uma área que traz consigo diversas questões difíceis e importantes da nossa sociedade. Uma destas questões, que remete ao possível descolamento da teoria do Direito e o que ocorre no mundo real, trata do cumprimento da pena. Considerando-se o plano ideal e o princípio de ampla defesa, mas também a conhecida morosidade dos tribunais, qual é o momento do processo em que deveria ser iniciado o cumprimento de pena? Será que a taxa de reforma das decisões é tão pequena a ponto de justificar o início do cumprimento de pena após a sentença na primeira instância? Com o objetivo de obter essas taxas, a presente pesquisa utiliza como base de dados um levantamento de 157.379 decisões em segunda instância, das quais 57.625 envolvem apelações contra o Ministério Público, todas proferidas entre 01/01/2014 e 31/12/2014 nas dezesseis Câmaras de Direito Criminal do Estado de São Paulo, e nas quatro Câmaras Extraordinárias. A Figura 2.1 mostra a distribuição dos resultados dos processos em relação aos órgãos julgadores. Aqui, encontramos discrepâncias enormes, onde podemos encontrar câmaras com mais de 75% de recursos negados (quarta e sexta) e câmaras com menos de 30% de recursos negados (primeira, segunda e décima segunda). Este resultado poderia ser explicado por duas hipóteses: os processos não são distribuídos aleatoriamente nas câmaras, e é feita uma triagem que envolve o tipo do recurso; ou os magistrados de cada câmara comportam-se de maneiras muito diferentes, mesmo para processos considerados homogêneos. Figura 2.1: Resultados por câmara. "],
["estudo-2-especializacao-de-varas-empresariais.html", "2.4 Estudo 2: Especialização de varas empresariais", " 2.4 Estudo 2: Especialização de varas empresariais 2.4.1 Contextualização Apesar do município de São Paulo ser o maior polo empresarial do Brasil, a comarca de São Paulo não possuía varas especializadas nessa matéria. Por outro lado, o provimento nº 82/2011 do TJSP define critérios para criação de varas: Uma vara só pode ser criada se o volume de trabalho esperado for maior do que 1.800 processos/ano. A análise deve levar em conta a complexidade dos feitos. Em levantamentos anteriores, foram observadas menos de 1.800 distribuições de processos em um ano e, portanto, não seria possível justificar a criação dessas varas. No entanto, é sabido que processos empresariais, em média, são mais complexos que processos cíveis. Por isso, faria sentido criar varas empresariais, ainda que a meta quantitativa não fosse atingida. Como verificar essa hipótese? Nesse estudo, buscamos formas de comparar a complexidade processos cíveis e empresariais. 2.4.2 Desafio adicional: cifra oculta Em estudos jurimétricos, até mesmo a pergunta “quantos processos empresariais são distribuídos por ano na comarca de São Paulo?” é complicada. Os registros são imprecisos e a classificação proposta pelo CNJ não é bem utilizada. Atualmente, a forma mais direta de identificar tipos de processos judiciais é utilizando os chamados assuntos processuais. Os assuntos relacionam-se com as matérias discutidas em cada caso. Por exemplo, um caso cível de indenização por dano moral poderia ter um assunto “Indenização por dano moral”, enquanto um processo falimentar de uma empresa em Recuperação Judicial poderia ser classificado como “Convocação de Recuperação Judicial em Falência”. Nesse contexto, um importante passo foi dado com a Resolução 46/2007 do CNJ1, que criou as TPUs. As TPUs são uma documentação oficial de todas as classes, assuntos e movimentações dos processos. As TPUs foram implantadas em todas as Justiças, o que facilita a realização de análises que comparam diferentes tribunais. A Figura ?? mostra uma parte das TPUs do CNJ. As TPUs são estruturadas em formato de árvore. Isso significa que temos assuntos genéricos e assuntos específicos, sendo que o assunto específico é um filho do assunto genérico. As TPUs podem ter até seis níveis hierárquicos de assuntos. O problema enfrentado atualmente é que, na prática, nem sempre os processos são classificados com assuntos específicos. Assim, podemos ter um caso que discute sobre “Análise de Crédito” classificado como “Responsabilidade do Fornecedor”, ou ainda “Direito do Consumidor”. A existência de casos classificados com assuntos genéricos implica num problema para o levantamento do volume processual por assunto. Por exemplo, considere que há interesse em conhecer o volume de processos envolvendo “Análise de Crédito”. Se considerarmos somente os casos classificados corretamente, estaríamos subestimando o real volume de processos, pois estaríamos ignorando os casos classificados em assuntos genéricos. Por outro lado, se considerarmos no levantamento todos os casos, incluindo os genéricos, estaríamos superestimanto o real volume. A possibilidade de subestimação do volume real de processos de um certo tipo configura o que chamamos de cifra oculta. Dado um assunto específico, esse número pode ser definido como a quantidade de processos com esse assunto, mas classificados em assuntos genéricos. Felizmente, a cifra oculta pode ser estimada. Para isso, no entanto, é necessário fazer algumas suposições ou utilizar conhecimentos a priori sobre os processos. A forma mais simples de estimar a cifra oculta é realizando uma espécie de regra de três. No exemplo da análise de crédito, considere que temos uma base de dados com todos os casos classificados com assuntos dentro da árvore do “Direito do Consumidor”. Suponha também que todos os processos de análise de crédito foram classificados ou corretamente, ou incorretamente como “Direito do Consumidor”. Utilizando somente a parte da base que foi classificada com assuntos específicos, estimamos a proporção de casos \\(p\\) classificados como “Análise de Crédito”. Assim, uma estimativa do volume de processos de análise de crédito é dada por \\[ N_{\\text{cred}}=N_A+N_T\\times p, \\text{onde} \\] \\(N_A\\) é o volume de casos classificados corretamente como “Análise de Crédito”. \\(N_T\\) é o volume total de casos classificados como “Direito do Consumidor”. \\(N_T\\times p\\) é a estimativa da cifra oculta. Na nossa aplicação, isso foi feito estimando-se a probabilidade de um assunto genérico tratar da matéria empresarial, usando-se uma rede bayesiana. Para esse cálculo, utilizamos a parcela da base de dados que foi classificada corretamente e calculamos a proporção de processos empresariais para cada assunto. A cifra oculta é estimada somando-se as probabilidades obtidas. Nossos dados originais são: No Foro Central Cível foram distribuídos 675 processos empresariais por ano. Nos demais Foros foram distribuídos 450 processos por ano. Total: 1.125 processos/ano. Aplicando as correções, temos: No Foro Central Cível foram distribuídos 961 processos empresariais/ano. Nos demais Foros foram distribuídos 641 processos empresariais/ano. Total: 1.602 processos/ano. 2.4.3 Voltando à complexidade Agora vamos fazer comparações. O processo demora mais tempo como um todo? \\[ \\text{Complexidade} = \\text{Tempo entre distribuicao e sentenca} \\] O processo custa mais tempo aos magistrados? \\[ \\text{Complexidade} = \\text{Tempo entre conclusos e decisoes} \\] Nas duas métricas, processos empresariais são mais complexos. Comparando casos de dificuldade moderada, processos empresariais custam o dobro de tempo para magistrados e 30% a mais de tempo na tramitação total. Aplicando os critérios propostos, a carga de trabalho proporcionada pelos processos empresariais corresponde a - 2.082 processos comuns, considerando o custo em tramitação; - 3.349 processos comuns, considerando o tempo gasto pelos magistrados. http://www.cnj.jus.br/images/stories/docs_cnj/resolucao/rescnj_46.pdf. Acesso em 26/06/2017.↩ "],
["estudo-3-captchas.html", "2.5 Estudo 3: CAPTCHAs", " 2.5 Estudo 3: CAPTCHAs Apesar dos sistemas jurídicos serem públicos, seus dados não são acessíveis. Muitas vezes o acesso às páginas web são limitadas através de bloqueios de IP e Algumas justificativas para a existência de CAPTCHAs são: i) não onerar os sistemas ou ii) a ideia de que assim estão protegendo as pessoas. O primeiro argumento é frágil pois ambos poderiam ser resolvidos através de uma API de acesso público dos tribunais, ou mesmo uma API paga. O segundo argumento também é ruim, pois, ainda que limitado, esses dados serão obtidos e utilizados. Limitar o acesso só aumenta o custo para construção dessas bases, direcionando o poder para as empresas que têm mais dinheiro para investir nisso, causando viés no acesso à informação. Fazendo curta uma história longa, se um dado é público, ele deve ser acessível. Nos trabalhos da ABJ, esbarramos com CAPTCHAs inúmeras vezes. Recentemente, descobrimos formas de resolver CAPTCHAs automaticamente utilizando modelos estatísticos. Esses modelos são da recente (ou não) classe de modelos de deep learning, uma área que cresceu exponencialmente nos últimos anos. Incluímos esse exemplo no curso por dois motivos. Apesar de não ser um modelo jurimétrico, trata-se de um problema presente no contexto da jurimetria, logo é um conhecimento útil. Além disso, a técnica utilizada para quebrar CAPTCHAs é muito interessante e poderia ser adaptada para diversos contextos, inclusive estudos jurimétricos. Nossas soluções para quebrar captchas foram consolidadas num pacote chamado decryptr. Vamos discutir brevemente como ele foi criado e como usar. Também discutiremos superficialmente o modelo de redes neurais utilizado e como criar o seu próprio modelo. Veja um quebrador de captcha em funcionamento: "],
["cuidado.html", "2.6 Cuidado", " 2.6 Cuidado As bases de dados utilizadas em estudos jurimétricos foram originalmente concebidas para fins gerenciais e não analíticos. Por isso, observamos muitos dados faltantes, mal formatados e com documentação inadequada. Uma boa porção dos dados só está disponível em páginas HTML e arquivos PDF e grande parte da informação útil está escondida em textos. Chamamos esse fenômeno de “pré-sal sociológico”. Temos hoje diversas bases de dados armazenadas em repositórios públicos ou controladas pelo poder público, mas que precisam ser lapidadas para obtenção de informação útil. O jurimetrista trabalha com dados sujos e desorganizados, mas gera muito valor ao extrair suas informações. Por isso, o profissional precisa dominar o ferramental de extração, transformação e visualização de dados, e é sobre isso que discutiremos na primeira parte do curso. Utilizaremos como base o software estatístico R, que atualmente possui diversas ferramentas que ajudam nessas atividades. "],
["organizacao-do-curso.html", "2.7 Organização do curso", " 2.7 Organização do curso O curso foi montado em RMarkdown, usando um pacote chamado bookdown. O material é 100% reprodutível e está disseminado em diversos lugares no GitHub. As aulas foram organizadas pelo Ciclo de ciência de dados. Trabalharemos com o tidyverse Import: esaj e dje. Tidy / Transform: abjutils, dplyr, stringr, lubridate, forcats, tidyr e purrr. Visualize: ggplot2. Model: survival, bnlearn, keras "],
["configuracao-necessaria-para-o-curso.html", "2.8 Configuração necessária para o curso", " 2.8 Configuração necessária para o curso 2.8.1 Pacotes Para poder rodar os códigos do curso, é importante que você instale todos os pacotes relacionados a este livro. Para isso, basta rodar devtools::install_github(&quot;abjur/r4jurimetrics&quot;) Esse código teoricamente funciona pois este livro também é um pacote e adicionamos todas as dependências. Se você não conseguir instalar as dependências, abra o arquivo DESCRIPTION do material: https://github.com/abjur/r4jurimetrics/blob/master/DESCRIPTION Nesse aquivo constam todos os pacotes que estamos utilizando. Se algo deu errado na instalação do r4jurimetrics, é porquê pelo menos um desses pacotes deu erro na instalação. Note que os pacotes dentro de Remotes devem ser instalados com devtools::install_github(). Note também que os pacotes que estão no Remotes também estão no Imports. 2.8.2 Fork e upstream (experimental) Para fazer essa parte funcionar, você precisará de uma conta ativa no GitHub. Se você não tiver uma, recomendamos fortemente que criem. Agora siga os passos abaixo: Acesse no seu navegador: https://github.com/abjur/r4jurimetrics Certifique-se de que você está logado na sua conta. Dê um fork no repositório Volte ao RStudio Crie um projeto: Projetos &gt; New Project &gt; Version control &gt; git Na parte do link do repositório, coloque https://github.com//r4jurimetrics Dê OK e certifique-se de que o repositório foi criado. Abra um terminal: Tools &gt; Shell Arrume e rode git config --global user.email &quot;seuEmail&quot; e git config --global user.name &quot;seuLogin&quot; Esses comandos configuram seu usuário para registrar mudanças nos repositórios. Rode git remote add upstream https://github.com/abjur/r4jurimetrics.git Esse comando faz com que seu repositório fique ligado ao repositório original Rode git fetch upstream Esse comando baixa as atualizações do repositório pai, se houverem Rode git merge upstream/master -m &quot;merge with parent&quot; Esse comando juntar o seu repositório com o código do reporitório pai. Nesse momento podem acontecer conflitos. Se tiver algum problema, veja: https://help.github.com/articles/configuring-a-remote-for-a-fork/ https://help.github.com/articles/syncing-a-fork/ "],
["suas-tarefas-para-1701-demora-30-min.html", "2.9 Suas tarefas para 17/01 (demora 30 min)", " 2.9 Suas tarefas para 17/01 (demora 30 min) Entrar no grupo: t.me/rbrasil Cadastrar na newsletter da ABJ http://www.abj.org.br Ler blog: http://www.abj.org.br/blog/2017/01/27/2017-01-28-assuntos/ Ler blog: http://www.abj.org.br/blog/2016/12/31/2016-12-31-tempos/ Dar uma olhada em https://abjur.github.io/tjspBook Dar uma olhada em http://material.curso-r.com Dar uma olhada em https://tidyverse.org Dar uma olhada em http://r4ds.had.co.nz Dar uma olhada em https://github.com/abjur, https://github.com/courtsbr, https://github.com/curso-r "],
["importacao-de-dados.html", "Capítulo 3 Importação de dados", " Capítulo 3 Importação de dados Agora nós estamos aqui: Nessa parte, vamos aprender a baixar dados da web. No contexto da jurimetria, isso é muito importante por dois motivos: i) você nunca pode esperar que alguém ofereça esses dados organizados para você e ii) isso é muito divertido e é um aprendizado para a vida. 3.0.1 Setup Logar no servidor http://r.abj.org.br Novo projeto &gt; Version Control &gt; GIT Colocar a URL https://github.com/abjur/r4jurimetrics Iniciar projeto Abrir o arquivo 02-import.Rmd Rodar library(tidyverse) "],
["pipe.html", "3.1 Pipe %&gt;%", " 3.1 Pipe %&gt;% Considere o seguinte exemplo: f &lt;- function(x, y) x + y x &lt;- 1 y &lt;- 2 As duas linhas abaixo são equivalentes: f(x, y) #&gt; [1] 3 x %&gt;% f(y) #&gt; [1] 3 Exemplo: alcular raiz quadrada da soma dos valores de 1 a 4. x &lt;- c(1, 2, 3, 4) x %&gt;% sum() %&gt;% sqrt() #&gt; [1] 3.162278 Escrever esse cálculo na forma usual ficaria da seguinte forma: sqrt(sum(x)) #&gt; [1] 3.162278 3.1.1 Receita de bolo Tente entender o que é preciso fazer. esfrie( asse( coloque( bata( acrescente( recipiente(rep(&quot;farinha&quot;, 2), &quot;água&quot;, &quot;fermento&quot;, &quot;leite&quot;, &quot;óleo&quot;), &quot;farinha&quot;, até = &quot;macio&quot;), duração = &quot;3min&quot;), lugar = &quot;forma&quot;, tipo = &quot;grande&quot;, untada = TRUE), duração = &quot;50min&quot;), &quot;geladeira&quot;, &quot;20min&quot;) Desistiu? Agora veja como fica escrevendo com o %&gt;%: recipiente(rep(&quot;farinha&quot;, 2), &quot;água&quot;, &quot;fermento&quot;, &quot;leite&quot;, &quot;óleo&quot;) %&gt;% acrescente(&quot;farinha&quot;, até = &quot;macio&quot;) %&gt;% bata(duraço = &quot;3min&quot;) %&gt;% coloque(lugar = &quot;forma&quot;, tipo = &quot;grande&quot;, untada = TRUE) %&gt;% asse(duração = &quot;50min&quot;) %&gt;% esfrie(&quot;geladeira&quot;, &quot;20min&quot;) Agora o código realmente parece uma receita de bolo. Para mais informações sobre o pipe e exemplos de utilização, visite a página Ceci n’est pas un pipe. "],
["usando-o-inspect.html", "3.2 Usando o Inspect", " 3.2 Usando o Inspect Se você quer aprender a baixar dados da web, você precisa aprender a usar o Inspect do seu navegador. Para isso, vamos abrir a página do e-SAJ. Agora clique com o botão direito e depois em “inspecionar” (vamos assumir que você está usando o Google Chrome). Na tela que vai abrir, entre na aba “Network”. O navegador vai pedir que você atualize a página, apertando F5. Faça isso. Agora você verá uma lista de documentos que seu navegador baixou para carregar a página. O primeiro item dessa lista, consultaCompleta.do, contém informações da sua consulta processual. Clique nesse item. O conteúdo dessa página é a requisição web utilizada para acessar o e-SAJ. Basicamente, tudo o que faremos na parte de web scraping é tentar imitar o que esse site faz. Tenha em mente que, para construir um scraper, você usará duas ferramentas principais: seu navegador e o RStudio. "],
["pacotes-httr-xml2-e-rvest.html", "3.3 Pacotes httr, xml2 e rvest", " 3.3 Pacotes httr, xml2 e rvest Esses são os três pacotes mais modernos do R para fazer web scraping. O pacote xml2 tem a finalidade de estruturar arquivos HTML ou XML de forma eficiente, tornando possível a obtenção de tags e seus atributos dentro de um arquivo. Já o pacote httr é responsável por realizar requisições web para obtenção das páginas de interesse, buscando reduzir ao máximo a complexidade da programação. O pacote rvest é escrito sobre os dois anteriores e por isso eleva ainda mais o nível de especialização para raspagem de dados. A utilização dos pacotes tem uma regra de bolso. Para trabalhar com páginas simples, basta carregar o rvest e utilizar suas funcionalidades. Caso o acesso à página exija ações mais complexas e/ou artifícios de ferramentas web, será necessário utilizar o httr. O xml2 só será usado explicitamente nos casos em que a página está em XML. Esses pacotes não são suficientes para acessar todo tipo de conteúdo da web. Um exemplo claro disso são páginas em que o conteúdo é produzido por javascript, o que acontece em alguns sites modernos. Para trabalhar com esses sites, é necessário realmente “simular” um navegador que acessa a página web. Uma das melhores ferramentas para isso é o selenium. Não discutiremos selenium nesse curso, mas caso queira se aprofundar, acesse aqui e o pacote RSelenium. 3.3.1 GET e POST Uma requisição GET envia uma url ao servidor, possivelmente com alguns parâmetros nessa url (que ficam no final da url depois do ?). O servidor, por sua vez, recebe essa url, processa os parâmetros e retorna uma página HTML para o navegador2. A requisição POST, no entanto, envia uma url não modificada para o servidor, mas envia também uma lista de dados preenchidos pelo usuário, que podem ser números, textos ou até imagens. Na maioria dos casos, ao submeter um formulário de um site, fazemos uma requisição POST. O httr possui os métodos GET e POST implementados e são muito similares. A lista de parâmetros enviados pelo usuário pode ser armazenado numa list nomeada, e adicionado ao GET pelo parâmetro query ou no POST pelo parâmetro body. Exemplo de GET httr::GET(&quot;http://google.com/search&quot;, query = list(q = &quot;jurimetria&quot;)) #&gt; Response [http://www.google.com/search?q=jurimetria] #&gt; Date: 2018-01-24 11:21 #&gt; Status: 200 #&gt; Content-Type: text/html; charset=ISO-8859-1 #&gt; Size: 41.9 kB #&gt; &lt;!doctype html&gt;&lt;html itemscope=&quot;&quot; itemtype=&quot;http://schema.org/SearchResu... #&gt; statistics, to law. The subject has gained considerable currency in both... #&gt; States and Brazil. In the United States, the journal Jurimetrics is publ... #&gt; American Bar Association and Arizona State University. In Brazil, the fi... #&gt; focus&amp;nbsp;...&lt;/span&gt;&lt;br&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;g&quot;&gt;&lt;h3 class=&quot;r&quot;&gt;&lt;a hre... #&gt; no Direito. Índice. [esconder]. 1 Histórico; 2 Os Três Prismas da &lt;b&gt;Jur... #&gt; Elaboração Legislativa e Gestão Pública; 2.2 A Decisão Judicial; 2.3 A I... #&gt; Probatória. 3 &lt;b&gt;Jurimetria&lt;/b&gt; vs Law and Economics; 4 Referências; 5 L... #&gt; bem como tece considerações e sugestões relevantes de aplicações prática... #&gt; teóricas do tema. É proposta a divisão da &lt;b&gt;jurimetria&lt;/b&gt; em três pris... #&gt; ... Exemplo de POST httr::POST(&quot;http://httpbin.org/post&quot;, body = list(x = &quot;Mãe to na request&quot;), encode = &quot;json&quot;) #&gt; Response [http://httpbin.org/post] #&gt; Date: 2018-01-24 11:21 #&gt; Status: 200 #&gt; Content-Type: application/json #&gt; Size: 528 B #&gt; { #&gt; &quot;args&quot;: {}, #&gt; &quot;data&quot;: &quot;{\\&quot;x\\&quot;:\\&quot;M\\u00e3e to na request\\&quot;}&quot;, #&gt; &quot;files&quot;: {}, #&gt; &quot;form&quot;: {}, #&gt; &quot;headers&quot;: { #&gt; &quot;Accept&quot;: &quot;application/json, text/xml, application/xml, */*&quot;, #&gt; &quot;Accept-Encoding&quot;: &quot;gzip, deflate&quot;, #&gt; &quot;Connection&quot;: &quot;close&quot;, #&gt; &quot;Content-Length&quot;: &quot;26&quot;, #&gt; ... 3.3.2 Exercícios Use o Inspect: Qual o método usado na pesquisa de jurisprudência do TJSP? Qual o método usado na busca avançada de diários de justiça do TJSP? 3.3.3 Sessões e cookies No momento que acessamos uma página web, o navegador baixa alguns arquivos que identificam nosso acesso à página. Esses arquivos são chamados cookies e são usados pelos sites para realizar diversas atividades, como carregar uma página pré-definida pelo usuário caso este acesse o site pela segunda vez ou fazer propagandas. O httr e o rvest já guardam esses cookies de forma automática, de forma que o usuário não precise sa preocupar com isso. Em casos raros, para construir o web scraper é necessário modificar esses cookies. Nesses casos, estude a função cookies() do httr. 3.3.4 Outras funções do httr Outras funções úteis: write_disk() para escrever uma requisição direto em disco, além de guardar na memória RAM. config() para adicionar configurações adicionais. Por exemplo, quando acessar uma página https com certificados inadequados numa requisição GET, rode GET('https://www...', config(ssl_verifypeer = FALSE)). oauth_app() para trabalhar com APIs. Não discutiremos conexão com APIs nesse curso, mas é um importante conceito a ser estudado. 3.3.5 Principais funções do rvest Para acessar páginas da web: html_session() abre uma sessão do usuário (baixa página, carrega cookies etc). follow_link(), jump_to() acessa uma página web a partir de um link (tag &lt;a&gt;) ou url. html_form() carrega todos os formulários contidos numa página. set_value() atribui valores a parâmetros do formulário. submit_form() submete um formulário obtido em html_form. Para trabalhar com arquivos HTML: read_html() lê o arquivo HTML de forma estruturada e facilita impressão. html_nodes() cria uma lista com os nós identificados por uma busca em CSS path ou XPath. html_node() é um caso especial que assume que só será encontrado um resultado. html_text() extrai todo o conteúdo de um objeto e retorna um texto. html_table() extrai o conteúdo de uma &lt;table&gt; e transforma em um data_frame. html_attr() extrai um atributo de uma tag, por exemplo href da tag &lt;a&gt;. Se quiser ver exemplos, entre em http://material.curso-r.com/scrape/ 3.3.6 CSS path e XPath O CSS path e o XPath são formas distintas de buscar tags dentro de um documento HTML. O CSS path é mais simples de implementar e tem uma sintaxe menos verborrágica, mas o XPath é mais poderoso. A regra de bolso é tentar fazer a seleção primeiro em CSS e, caso não seja possível, implementar em XPath. Esses paths serão mostrados en passant durante o curso, mas não serão abordados em detalhe. Caso queira se aprofundar no assunto, comece pela ajuda da função ?html_nodes. para entender sobre server side e user side, acesse server side e user side.↩ "],
["melhores-praticas-para-web-scraping.html", "3.4 Melhores práticas para web scraping", " 3.4 Melhores práticas para web scraping É importante ressaltar que só estamos trabalhando com dados públicos. Caso tenha interesse em raspar páginas que precisam de autenticação ou uma página .com, recomendamos que estude os termos de uso do site. Nessa parte, trabalharemos principalmente com a Consulta de Jurisprudência e a Consulta de de Processos de Segundo Grau do TJSP, mas também teremos um pouco de pesquisas nos diários oficiais. 3.4.1 Informações iniciais Antes de iniciar um scraper, verifique se existe alguma forma mais fácil de conseguir os dados que necessita. Construir um web scraper do zero é muitas vezes uma tarefa dolorosa e, caso o site seja atualizado, pode ser que boa parte do trabalho seja inútil. Se os dados precisarem ser extraídos apenas uma vez, verifique com os responsáveis pela manutenção do site se eles podem fazer a extração que precisa. Se os dados precisarem ser atualizados, verifique se a entidade não possui uma API para acesso aos dados. Ao escrever um web scraper, as primeiras coisas que devemos pensar são, nessa porgem Qual o caminho percorrido para acessar uma página específica. Como o site a ser acessado foi contruído, se tem limites de requisições, utilização de cookies, states, etc. Como e com que frequência o site é atualizado, tanto em relação à sua interface como em relação aos dados que queremos extrair. Em sites dos tribunais, uma boa prática é dividir as atividades em três grupos principais: i) listar; ii) coletar e iii) processar. Quando já sabemos de antemão quais são os processos que vamos acessar, a etapa de listagem é desnecessária. Deixamos os algoritmos de coleta e processamento dos dados em funções distintas para aumentar o controle sobre o que as ferramentas estão fazendo. Isso facilita o debug e a atualização. Por outro lado, em alguns casos isso pode tornar o código ineficiente e os dados brutos obtidos podem ficar pesados. "],
["listando-processos.html", "3.5 Listando processos", " 3.5 Listando processos A forma de listar processos muda se seu estudo é prospectivo ou retrospectivo. Se o estudo for prospectivo, precisamos baixar dados dos Diários de Justiça Eletrônicos (DJE), que são arquivos PDF enormes. Se o estudo for retrospectivo, precisamos baixar dados da Consulta de Julgados de Segundo Grau (CJSG), que é um formulário na internet, mais simples. Se o seu estudo é retrospectivo, use esaj::download_cjsg(). CJSG significa Consulta de Julgados de Segundo Grau. Se o seu estudo é prospectivo, usedje::download_dje(). DJE significa Diário de Justiça Eletrônico "],
["usando-o-esaj-para-listar-processos.html", "3.6 Usando o esaj para listar processos", " 3.6 Usando o esaj para listar processos A CJSG possui vários parâmetros para consulta de decisões. As mais usadas são Palavras-chave Classe, assunto e câmaras Intervalos de datas 3.6.1 Pesquisa por palavras-chave A pesquisa por palavras-chave não tem segredo. Basta você seguir as especificações deste link. É importante ressaltar alguns pontos O e-SAJ não disponibiliza seu tesauro (dicionário estruturado) publicamente. Ou seja, você terá de confiar na pesquisa por sinônimos. Você não pode fazer uma busca completamente vazia. Ou você coloca a palavra-chave, ou você especifica outro parâmetro. Você pode pesquisar o termo a OU (NAO a), se quiser ;) 3.6.2 Pesquisa por datas Você pode usar duas datas para indexar os processos de sua pesquisa. A data de registro é a data em que o serventuário inclui a decisão no sistema. A data de julgamento é a data em que o conjunto de desembargadores proferiram a decisão. Normalmente, a indexação aconteceria pela data de julgamento, já que queremos vincular os processos à sua data final, não em relação à uma data do sistema. No entanto, as pesquisas indexadas pela data de julgamento não são completamente reprodutíveis, já que à medida que o tempo passa, mais decisões são registradas, mudando a base de julgados. Regra de bolso: Use data de registro se quiser ter certeza de que você pegou todos os casos em um determinado intervalo de tempo. Use data de julgamento se você estiver pesquisando casos mais antigos (por exemplo, de 2016 para trás), já que a quantidade de decisões não registradas nesse escopo é negligenciável. 3.6.3 Tabelas de classes, assuntos e câmaras Classes e assuntos definem, respectivamente, os ritos processuais e os tipos processuais. As câmaras são as casinhas dos desembargadores, que podem ser ordinárias (fixas) ou extraordinárias (eventuais, criadas por diferentes motivos). As classes e assuntos são definidas em formato de árvore. Cada nível dessa árvore tem uma lista de classes/assuntos e seus respectivos códigos. As tabelas de classes/assuntos podem ser obtidas pela função esaj::cjsg_table(). # Não rode esses códigos. Eles baixam os dados diretos da web classes &lt;- esaj::cjsg_table(&quot;classes&quot;) assuntos &lt;- esaj::cjsg_table(&quot;subjects&quot;) Já baixamos essas tabelas e colocamos em arquivos .rds (você sabe o que é um arquivo .rds?) classes &lt;- readRDS(&quot;data/cjsg_classes.rds&quot;) assuntos &lt;- readRDS(&quot;data/cjsg_assuntos.rds&quot;) glimpse(assuntos) #&gt; Observations: 3,088 #&gt; Variables: 12 #&gt; $ name0 &lt;chr&gt; &quot;0 - Assunto não Especificado&quot;, &quot;14 - DIREITO TRIBUTÁRIO... #&gt; $ id0 &lt;chr&gt; &quot;0&quot;, &quot;14&quot;, &quot;14&quot;, &quot;14&quot;, &quot;14&quot;, &quot;14&quot;, &quot;14&quot;, &quot;14&quot;, &quot;14&quot;, &quot;14... #&gt; $ name1 &lt;chr&gt; NA, &quot;5913 - Limitações ao Poder de Tributar&quot;, &quot;5913 - Li... #&gt; $ id1 &lt;chr&gt; NA, &quot;5913&quot;, &quot;5913&quot;, &quot;5913&quot;, &quot;5913&quot;, &quot;5913&quot;, &quot;5913&quot;, &quot;591... #&gt; $ name2 &lt;chr&gt; NA, &quot;5914 - Imunidade&quot;, &quot;5914 - Imunidade&quot;, &quot;5914 - Imun... #&gt; $ id2 &lt;chr&gt; NA, &quot;5914&quot;, &quot;5914&quot;, &quot;5914&quot;, &quot;5914&quot;, NA, NA, NA, NA, NA, ... #&gt; $ name3 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ... #&gt; $ id3 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ... #&gt; $ name4 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ... #&gt; $ id4 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ... #&gt; $ name5 &lt;chr&gt; &quot;0 - Assunto não Especificado&quot;, &quot;10527 - Livros / Jornai... #&gt; $ id5 &lt;chr&gt; &quot;0&quot;, &quot;10527&quot;, &quot;10528&quot;, &quot;10529&quot;, &quot;10530&quot;, &quot;5915&quot;, &quot;10540&quot;... Na prática, você vai procurar os assuntos que quer nessa tabela, obter os respectivos códigos e guardar em um vetor. Cuidado: Lembre-se da cifra oculta! Além disso, muitos casos têm assunto vazio. A tabela de câmaras segue a mesma regra. A única diferença é que não existem níveis, logo você só precisará procurar os nomes em uma coluna camaras &lt;- esaj::cjsg_table(&quot;courts&quot;) camaras &lt;- readRDS(&quot;data/cjsg_camaras.rds&quot;) glimpse(camaras) #&gt; Observations: 1,208 #&gt; Variables: 3 #&gt; $ branch &lt;chr&gt; &quot;DIREITO PÚBLICO&quot;, &quot;DIREITO PÚBLICO&quot;, &quot;DIREITO PÚBLICO&quot;... #&gt; $ court &lt;chr&gt; &quot;1.ª Câmara Direito Público B&quot;, &quot;1.º Grupo Direito Públ... #&gt; $ id &lt;chr&gt; &quot;0-434&quot;, &quot;0-438&quot;, &quot;0-439&quot;, &quot;0-57&quot;, &quot;0-209&quot;, &quot;0-1202&quot;, &quot;... 3.6.4 A função download_cjsg Com o escopo em mãos, podemos finalmente começar a baixar dados. Esses são os argumentos da função esaj::download_cjsg(). Veja a documentação ?esaj::download_cjsg args(esaj::download_cjsg) #&gt; function (query, path = &quot;.&quot;, classes = &quot;&quot;, subjects = &quot;&quot;, courts = &quot;&quot;, #&gt; trial_start = &quot;&quot;, trial_end = &quot;&quot;, registration_start = &quot;&quot;, #&gt; registration_end = &quot;&quot;, min_page = 1, max_page = 1, cores = 1, #&gt; wait = 0.5, tj = &quot;tjsp&quot;) #&gt; NULL Esse código baixa duas páginas da pesquisa de jurisprudência usando a palavra-chave homicídio, salvando os arquivos HTML na pasta data-raw/cjsg esaj::download_cjsg(&quot;homicídio&quot;, &quot;data-raw/cjsg&quot;, max_page = 2) Onde guardar os dados? Ao construir um scraper, é importante guardar os dados brutos na máquina ou num servidor, para reprodutibilidade e manutenção do scraper. Se estiver construindo um pacote do R, o melhor lugar para guardar esses dados é na pasta data-raw, como sugerido no livro r-pkgs. Se os dados forem muito volumosos, pode ser necessário colocar esses documentos numa pasta externa ao pacote. 3.6.5 Exercícios Faça o download das páginas 2 à 5 de uma pesquisa com palavra-chave igual ao seu nome. Descubra quantos resultados tem a sua pesquisa usando a função esaj::peek_cjsg(). 3.6.6 Arrumando os dados Para transformar os arquivos HTML em bases de dados prontas para análise, você precisa rodar esaj::parse_cjsg(). files &lt;- dir(&quot;data-raw/cjsg&quot;, full.names = TRUE, pattern = &quot;page&quot;) d_cjsg &lt;- esaj::parse_cjsg(files) glimpse(d_cjsg) #&gt; Observations: 40 #&gt; Variables: 13 #&gt; $ file &lt;chr&gt; &quot;data-raw/cjsg/page1.html&quot;, &quot;data-raw/cjsg/pag... #&gt; $ id_page &lt;chr&gt; &quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;5&quot;, &quot;6&quot;, &quot;7&quot;, &quot;8&quot;, &quot;9&quot;, &quot;... #&gt; $ id_decision &lt;chr&gt; &quot;11103571&quot;, &quot;11103186&quot;, &quot;11103116&quot;, &quot;11102507&quot;... #&gt; $ id_lawsuit &lt;chr&gt; &quot;2234431-52.2017.8.26.0000&quot;, &quot;2243740-97.2017.... #&gt; $ class_subject &lt;chr&gt; &quot;Classe/Assunto:\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t Habea... #&gt; $ district &lt;chr&gt; &quot;São Paulo&quot;, &quot;Olímpia&quot;, &quot;Mongaguá&quot;, &quot;Pirajuí&quot;,... #&gt; $ court &lt;chr&gt; &quot;6ª Câmara de Direito Criminal&quot;, &quot;6ª Câmara de... #&gt; $ dt_decision &lt;chr&gt; &quot;11/01/2018&quot;, &quot;11/01/2018&quot;, &quot;14/12/2017&quot;, &quot;11/... #&gt; $ dt_publication &lt;chr&gt; &quot;12/01/2018&quot;, &quot;12/01/2018&quot;, &quot;12/01/2018&quot;, &quot;11/... #&gt; $ dt_registration &lt;chr&gt; &quot;12/01/2018&quot;, &quot;12/01/2018&quot;, &quot;12/01/2018&quot;, &quot;11/... #&gt; $ rapporteur &lt;chr&gt; &quot;Ricardo Tucunduva&quot;, &quot;Ricardo Tucunduva&quot;, &quot;Ama... #&gt; $ summary &lt;chr&gt; NA, NA, &quot;TRÁFICO DE DROGAS – recurso do minis... #&gt; $ txt_summary &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA... 3.6.7 Exercícios Na pesquisa que você fez, qual é a comarca de origem mais frequente? Qual a diferença entre summary e txt_summary? "],
["usando-o-dje-para-listar-processos.html", "3.7 Usando o dje para listar processos", " 3.7 Usando o dje para listar processos O pacote dje baixa e lê diários de justiça eletrônicos. Com ele é possível baixar os PDFs e arrumá-los para obter uma base semi-estruturada. A função dje::download_dje() baixa os diários referentes a um dia. No TJSP, temos seis cadernos do diário, que são salvos em arquivos separados: 11: Judicial - 2a instância 12: Judicial - 1a instância - capital 18: Judicial - 1a instância - interior parte 1 13: Judicial - 1a instância - interior parte 2 15: Judicial - 1a instância - interior parte 3 14: Editais e Leilões dje::download_dje(&quot;TJSP&quot;, dates = &quot;2018-01-12&quot;, path = &quot;data-raw/dje&quot;) 3.7.1 Exercício O que acontece quando você tenta baixar um DJE de um dia num final de semana ou feriado? 3.7.2 Parse DJE Para parsear o DJE, primeiro você precisa transformar os PDF em textos: dje::dje_to_text(&quot;data-raw/dje/tjsp_dje_2018-01-12&quot;) E depois você aplica a função dje::parse_dje_tjsp() para ler os textos # para pegar somente 1a instancia patterns &lt;- glue::glue(&quot;_{c(12, 13, 15, 18)}_&quot;) %&gt;% glue::collapse(&quot;|&quot;) #arquivos dje_files &lt;- dir(&quot;data-raw/dje/tjsp_dje_2018-01-12_txt&quot;, full.names = TRUE, pattern = patterns) # veremos purrr nas próximas aulas! d_dje &lt;- purrr::map_dfr(dje_files, dje::parse_dje_tjsp) glimpse(d_dje) #&gt; Observations: 11,799 #&gt; Variables: 3 #&gt; $ classe &lt;chr&gt; &quot;\\nFórum João Mendes Júnior\\n&quot;, &quot;\\nFórum João Mendes... #&gt; $ valor &lt;chr&gt; &quot;\\nDistribuidor Cível\\n&quot;, &quot;\\nDistribuidor Cível\\n&quot;, ... #&gt; $ processos &lt;chr&gt; &quot;\\nDistribuidor Cível\\nRELAÇÃO DOS FEITOS CÍVEIS DIS... "],
["baixando-documentos.html", "3.8 Baixando documentos", " 3.8 Baixando documentos Baixar documentos, no entando, significa simplesmente acessar pesquisas de processos individuais e salvá-las em disco. Em algumas situações, os documentos baixados (depois de limpos) podem conter uma nova lista de documentos a serem baixadas, formando iterações de coletas. A tarefa de baixar documentos pré-estabelecidos será realizada pelas funções esaj::download_cposg(), esaj::download_cpopg() e esaj::download_decision(). 3.8.1 Download CPOSG As funções de download de processos recebem um vetor de números e baixam um HTML para cada deles. Às vezes um número de processo corresponde a mais do que um documento. Nesse caso, ambos os documentos são baixados, adicionando-se identificação de data. processos &lt;- unique(d_cjsg$id_lawsuit) esaj::download_cposg(processos, &quot;data-raw/cposg&quot;) 3.8.2 Baixando decisões Se o seu estudo é retrospectivo, você também pode baixar as decisões (sentenças ou acórdãos) do processo, em PDF. O código a ser rodado nesse caso é acordaos &lt;- d_cjsg$id_decision esaj::download_decision(acordaos) Por trás da função esaj::download_decision() estamos quebrando um CAPTCHA. Essa função ainda está instável, então pode ser necessário rodá-la várias vezes para obter os documentos finais. "],
["processando-documentos.html", "3.9 Processando documentos", " 3.9 Processando documentos Finalmente, processar documentos significa carregar dados acessíveis em disco e transformar os dados brutos uma base tidy. Usualmente separamos a estruturação em duas etapas: i) transformar arquivos não-estruturados em um arquivos semi-estruturados (e.g. um arquivo HTML em uma tabela mais um conjunto de textos livres) e ii) transformar arquivos semi-estruturados em uma base analítica (estruturada). A tarefa de processar as páginas HTML será realizada pelas funções esaj::parse_cjsg() e esaj::run_parser(). 3.9.1 Parse CPOSG O parser da consulta de processos foi escrito de um jeito especial. Uma página de resultados tem vários blocos de informações, entre eles i) dados básicos, ii) partes, iii) movimentações e iv) decisões. Em algumas pesquisas, temos interesse em apenas uma parte desses blocos. O parser foi construído para modular essa captura de informações. Outra diferença importante é que, nesse caso, salvamos individualmente os resultados do parse em arquivos .rds. Isso é feito para evitar retrabalho, já que esse processo é computacionalmente intensivo e o algoritmo pode travar no meio da execução. # lista de arquivos files_cposg &lt;- dir(&quot;data-raw/cposg&quot;, full.names = TRUE) # objeto de parse parser &lt;- esaj::make_parser() %&gt;% esaj::parse_data() %&gt;% esaj::parse_parts() %&gt;% esaj::parse_movs() %&gt;% esaj::parse_decisions() # rodar parse d_cposg &lt;- esaj::run_parser(file = files_cposg, parser = parser, path = &quot;data-raw/cposg_rds&quot;) Para obter a base de dados, basta ler e empilhar os arquivos parciais que foram gerados. rds_files &lt;- dir(&quot;data-raw/cposg_rds&quot;, full.names = TRUE) d_cposg &lt;- purrr::map_dfr(rds_files, readRDS) glimpse(d_cposg) #&gt; Observations: 41 #&gt; Variables: 7 #&gt; $ id &lt;chr&gt; &quot;00000091520158260558&quot;, &quot;00003442220148260347&quot;, &quot;000... #&gt; $ file &lt;chr&gt; &quot;data-raw/cposg/00000091520158260558.html&quot;, &quot;data-ra... #&gt; $ hidden &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FAL... #&gt; $ data &lt;list&gt; [&lt;# A tibble: 13 x 2, data value ... #&gt; $ parts &lt;list&gt; [&lt;# A tibble: 3 x 4, id name ... #&gt; $ movs &lt;list&gt; [&lt;# A tibble: 23 x 2, movement description ... #&gt; $ decisions &lt;list&gt; [&lt;# A tibble: 1 x 2, date decision ... 3.9.2 Exercícios Estude o objeto d_cposg. O que temos na coluna data? E na coluna parts? Qual é o outro parâmetro da função esaj::run_parser(), e o que ele faz? OBS: Os objetos data, parts, movs e decisions do d_cposg são chamados de list columns. "],
["pacote-abjutils.html", "3.10 Pacote abjutils", " 3.10 Pacote abjutils 3.10.1 Trabalhando com números de processos O número identificador de um processo judicial utilizado atualmente pelos tribunais é chamado número CNJ, criado na Resolução 65 do CNJ. A resolução define o padrão NNNNNNN-DD.AAAA.J.TR.OOOO, descrito abaixo. NNNNNNN: Número identificador do processo. DD: Dígito verificador gerado a partir da aplicação do algoritmo Módulo 97 Base 10, conforme Norma ISO 7064:2003. AAAA: Ano do ajuizamento do processo. J: Segmento do poder judiciário. No nosso caso, esse número é sempre 8, que identifica a Justiça Estadual. TR: Identifica o tribunal. No nosso caso, esse número é sempre 26 (TJSP). OOOO: Identifica a unidade de origem do processo. No nosso caso, as possíveis configurações identificam os foros de São Paulo. Na maioria dos casos, o número também identifica a comarca, pois existem poucas comarcas com mais de um foro (e.g. a comarca de São Paulo, que possui mais de dez foros regionais). id_montado &lt;- &quot;0000009-15.2015.8.26.0558&quot; id_limpo_dig &lt;- &quot;00000091520158260558&quot; id_limpo_ndig &lt;- &quot;000000920158260558&quot; As funções abjutils::build_id() e abjutils::clean_id() montam ou limpam o número do processo. abjutils::build_id(id_limpo_dig) #&gt; [1] &quot;0000009-15.2015.8.26.0558&quot; abjutils::clean_id(id_montado) #&gt; [1] &quot;00000091520158260558&quot; A função abjutils::extract_parts() extrai todos os componentes do número do processo. abjutils::extract_parts(id_montado) #&gt; [[1]] #&gt; N D A J T O #&gt; &quot;0000009&quot; &quot;15&quot; &quot;2015&quot; &quot;8&quot; &quot;26&quot; &quot;0558&quot; A função abjutils::separate_cnj() faz o mesmo, mas em uma coluna do banco de dados d_cjsg %&gt;% abjutils::separate_cnj(&quot;id_lawsuit&quot;, remove = FALSE) %&gt;% glimpse() #&gt; Observations: 40 #&gt; Variables: 19 #&gt; $ file &lt;chr&gt; &quot;data-raw/cjsg/page1.html&quot;, &quot;data-raw/cjsg/pag... #&gt; $ id_page &lt;chr&gt; &quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;5&quot;, &quot;6&quot;, &quot;7&quot;, &quot;8&quot;, &quot;9&quot;, &quot;... #&gt; $ id_decision &lt;chr&gt; &quot;11103571&quot;, &quot;11103186&quot;, &quot;11103116&quot;, &quot;11102507&quot;... #&gt; $ id_lawsuit &lt;chr&gt; &quot;2234431-52.2017.8.26.0000&quot;, &quot;2243740-97.2017.... #&gt; $ N &lt;chr&gt; &quot;2234431&quot;, &quot;2243740&quot;, &quot;0001328&quot;, &quot;0058527&quot;, &quot;0... #&gt; $ D &lt;chr&gt; &quot;52&quot;, &quot;97&quot;, &quot;12&quot;, &quot;52&quot;, &quot;22&quot;, &quot;50&quot;, &quot;23&quot;, &quot;50&quot;... #&gt; $ A &lt;chr&gt; &quot;2017&quot;, &quot;2017&quot;, &quot;2015&quot;, &quot;2017&quot;, &quot;2015&quot;, &quot;2013&quot;... #&gt; $ J &lt;chr&gt; &quot;8&quot;, &quot;8&quot;, &quot;8&quot;, &quot;8&quot;, &quot;8&quot;, &quot;8&quot;, &quot;8&quot;, &quot;8&quot;, &quot;8&quot;, &quot;... #&gt; $ T &lt;chr&gt; &quot;26&quot;, &quot;26&quot;, &quot;26&quot;, &quot;26&quot;, &quot;26&quot;, &quot;26&quot;, &quot;26&quot;, &quot;26&quot;... #&gt; $ O &lt;chr&gt; &quot;0000&quot;, &quot;0000&quot;, &quot;0366&quot;, &quot;0000&quot;, &quot;0572&quot;, &quot;0554&quot;... #&gt; $ class_subject &lt;chr&gt; &quot;Classe/Assunto:\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t Habea... #&gt; $ district &lt;chr&gt; &quot;São Paulo&quot;, &quot;Olímpia&quot;, &quot;Mongaguá&quot;, &quot;Pirajuí&quot;,... #&gt; $ court &lt;chr&gt; &quot;6ª Câmara de Direito Criminal&quot;, &quot;6ª Câmara de... #&gt; $ dt_decision &lt;chr&gt; &quot;11/01/2018&quot;, &quot;11/01/2018&quot;, &quot;14/12/2017&quot;, &quot;11/... #&gt; $ dt_publication &lt;chr&gt; &quot;12/01/2018&quot;, &quot;12/01/2018&quot;, &quot;12/01/2018&quot;, &quot;11/... #&gt; $ dt_registration &lt;chr&gt; &quot;12/01/2018&quot;, &quot;12/01/2018&quot;, &quot;12/01/2018&quot;, &quot;11/... #&gt; $ rapporteur &lt;chr&gt; &quot;Ricardo Tucunduva&quot;, &quot;Ricardo Tucunduva&quot;, &quot;Ama... #&gt; $ summary &lt;chr&gt; NA, NA, &quot;TRÁFICO DE DROGAS – recurso do minis... #&gt; $ txt_summary &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA... A função abjutils::calc_dig() calcula o dígito verificador do processo a partir do número incompleto. A função abjutils::check_dig() checa se o dígito do processo está correto. Essas funções são úteis para i) gerar números de processo aleatórios e ii) arrumar erros de parse, por exemplo, o resultado da leitura de um DJE ou de um PDF escaneado. abjutils::calc_dig(id_limpo_ndig) #&gt; [1] &quot;15&quot; abjutils::check_dig(id_montado) #&gt; [1] TRUE Finalmente, a função abjutils::sample_cnj() serve para criar amostras de números de processos. Esses pocessos podem ser manifestos ou não. Em algumas pesquisas mais complicadas (e.g. nossa pesquisa sobre processamento de homicídios) esse tipo de abordagem é necessária. set.seed(1) abjutils::sample_cnj(n = 10, foros = &quot;0001&quot;, anos = 2015:2017, orgao = &quot;8&quot;, tr = &quot;26&quot;, first_dig = 0, return_df = FALSE) %&gt;% abjutils::build_id() #&gt; [1] &quot;0205974-12.2015.8.26.0001&quot; &quot;0176556-92.2016.8.26.0001&quot; #&gt; [3] &quot;0687022-88.2016.8.26.0001&quot; &quot;0384103-68.2017.8.26.0001&quot; #&gt; [5] &quot;0769841-19.2015.8.26.0001&quot; &quot;0497699-30.2017.8.26.0001&quot; #&gt; [7] &quot;0717618-21.2017.8.26.0001&quot; &quot;0991906-87.2016.8.26.0001&quot; #&gt; [9] &quot;0380035-12.2016.8.26.0001&quot; &quot;0777445-31.2015.8.26.0001&quot; 3.10.2 Trabalhando com acentos A função abjutils::rm_accent() serve para tirar acentos de um texto abjutils::rm_accent(&quot;Têxto cóm açèntõs&quot;) #&gt; [1] &quot;Texto com acentos&quot; Só isso! Mas extremamente útil. Outra versão dessa função pode ser encontrada no pacote rslp. Para quem é desenvolvedor de pacotes, a função abjutils::escape_unicode() é muito útil: ela transforma todos os acentos em códigos do tipo \\uxxxx, permitindo que o pacote funcione em diferentes plataformas, sem os famosos problemas de encoding. Essa função não é para ser utilizada diretamente, mas sim como um addin do RStudio. "],
["wrap-up.html", "3.11 Wrap-up", " 3.11 Wrap-up Nessa aula, vimos Definição do pipe %&gt;% Um pouco sobre web scraping Usar o inspect! pacotes httr, xml2 e rvest Scrapers jurimétricos listar números com dje::download_dje() e esaj::download_cj*g(). coletar documentos com esaj::download_cpo*g(). processar documentos com esaj::run_parser(). Pacote abjutils Trabalhando com número CNJ Trabalhando com acentos: abjutils::rm_accent() Na próxima vez, vamos trabalhar as bases de dados obtidas, estudar expressões regulares e mais alguns pacotes do tidyverse. "],
["transformacao-de-dados-1.html", "Capítulo 4 Transformação de dados 1", " Capítulo 4 Transformação de dados 1 “(…) The fact that data science exists as a field is a colossal failure of statistics. To me, [what I do] is what statistics is all about. It is gaining insight from data using modelling and visualization. Data munging and manipulation is hard and statistics has just said that’s not our domain.” Hadley Wickham Nessa parte, vamos aprender a arrumar dados baixados da web. No contexto da jurimetria, isso é muito importante por dois motivos: i) é difícil, pois as bases não foram concebidas para isso e ii) nessa parte conseguimos para explorar todas as maravilhas do tidyverse. 4.0.1 Setup Logar no servidor http://r.abj.org.br Novo projeto &gt; Version Control &gt; GIT Colocar a URL https://github.com/abjur/r4jurimetrics Iniciar projeto Abrir o arquivo 03-vectors.Rmd Rodar library(tidyverse) "],
["revisao.html", "4.1 Revisão", " 4.1 Revisão Obtenção dos nossos dados library(tidyverse) library(esaj) library(glue) library(abjutils) path &lt;- &quot;data-raw/camaras&quot; # onde salvar? dir.create(path, showWarnings = FALSE) Quais câmaras vamos baixar? OBS: Usa um pouco de stringr e dplyr, que veremos adiante. # camaras &lt;- cjsg_table(&quot;courts&quot;) camaras &lt;- read_rds(&quot;data/cjsg_camaras.rds&quot;) id_camaras &lt;- camaras %&gt;% filter(str_detect(court, &quot;Câmara.*Direito Criminal$&quot;)) %&gt;% pull(id) Quantas decisões no total? peek_cjsg(query = &quot;&quot;, courts = id_camaras, registration_start = &quot;2017-12-01&quot;, registration_end = &quot;2018-01-18&quot;) Baixando decisões: CJSG cjsg_path &lt;- glue(&quot;{path}/cjsg&quot;) download_cjsg(query = &quot;&quot;, path = cjsg_path, courts = id_camaras, registration_start = &quot;2017-12-01&quot;, registration_end = &quot;2018-01-18&quot;, max_page = Inf, wait = 0.8) cjsg_files &lt;- dir(cjsg_path, full.names = TRUE, pattern = &quot;page&quot;) # parse d_cjsg &lt;- parse_cjsg(cjsg_files) # salvando tibble parseada write_rds(d_cjsg, glue(&quot;{path}/d_cjsg.rds&quot;), compress = &quot;bz2&quot;) d_cjsg &lt;- read_rds(glue(&quot;{path}/d_cjsg.rds&quot;)) glimpse(d_cjsg) #&gt; Observations: 11,731 #&gt; Variables: 14 #&gt; $ file &lt;chr&gt; &quot;data-raw/camaras/cjsg/page100.html&quot;, &quot;data-ra... #&gt; $ id_page &lt;chr&gt; &quot;1981&quot;, &quot;1982&quot;, &quot;1983&quot;, &quot;1984&quot;, &quot;1985&quot;, &quot;1986&quot;... #&gt; $ id_decision &lt;chr&gt; &quot;11094999&quot;, &quot;11093733&quot;, &quot;11093677&quot;, &quot;11093270&quot;... #&gt; $ id_lawsuit &lt;chr&gt; &quot;0057003-20.2017.8.26.0000&quot;, &quot;0052762-03.2017.... #&gt; $ class_subject &lt;chr&gt; &quot;Classe/Assunto:\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t Habea... #&gt; $ district &lt;chr&gt; &quot;Cosmópolis&quot;, &quot;São Paulo&quot;, &quot;Ribeirão Preto&quot;, &quot;... #&gt; $ court &lt;chr&gt; &quot;3ª Câmara de Direito Criminal&quot;, &quot;3ª Câmara de... #&gt; $ dt_decision &lt;chr&gt; &quot;19/12/2017&quot;, &quot;19/12/2017&quot;, &quot;19/12/2017&quot;, &quot;14/... #&gt; $ dt_publication &lt;chr&gt; &quot;19/12/2017&quot;, &quot;19/12/2017&quot;, &quot;19/12/2017&quot;, &quot;19/... #&gt; $ dt_registration &lt;chr&gt; &quot;19/12/2017&quot;, &quot;19/12/2017&quot;, &quot;19/12/2017&quot;, &quot;19/... #&gt; $ rapporteur &lt;chr&gt; &quot;Luiz Antonio Cardoso&quot;, &quot;Luiz Antonio Cardoso&quot;... #&gt; $ summary &lt;chr&gt; NA, NA, NA, &quot;Execução Penal – Comutação de Pe... #&gt; $ txt_summary &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA... #&gt; $ result &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA... Baixando processos: CPOSG cposg_path &lt;- glue(&quot;{path}/cposg&quot;) # baixando processos individuais d_cjsg %&gt;% filter(!is.na(id_lawsuit)) %&gt;% pull(id_lawsuit) %&gt;% unique() %&gt;% clean_id() %&gt;% download_cposg(cposg_path) cposg_files &lt;- dir(cposg_path, full.names = TRUE) # parse parser &lt;- make_parser() %&gt;% parse_data() %&gt;% parse_parts() %&gt;% parse_decisions() # esse parser salva intermediários em rds rds_path &lt;- glue(&quot;{path}/cposg_rds&quot;) run_parser(cposg_files, parser, path = rds_path) rds_files &lt;- dir(rds_path, full.names = TRUE) d_cposg &lt;- map_dfr(rds_files, read_rds) %&gt;% mutate(id_lawsuit = build_id(str_extract(id, &quot;^[0-9]+&quot;))) %&gt;% select(id, id_lawsuit, everything()) # salvando tibble parseada write_rds(d_cposg, glue(&quot;{path}/d_cposg.rds&quot;), compress = &quot;bz2&quot;) d_cposg &lt;- read_rds(glue(&quot;{path}/d_cposg.rds&quot;)) glimpse(d_cposg) #&gt; Observations: 11,762 #&gt; Variables: 7 #&gt; $ id &lt;chr&gt; &quot;00000037120168260073&quot;, &quot;00000040920178260142&quot;, &quot;00... #&gt; $ id_lawsuit &lt;chr&gt; &quot;0000003-71.2016.8.26.0073&quot;, &quot;0000004-09.2017.8.26.... #&gt; $ file &lt;chr&gt; &quot;data-raw/camaras/cposg/00000037120168260073.html&quot;,... #&gt; $ hidden &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FA... #&gt; $ data &lt;list&gt; [&lt;# A tibble: 11 x 2, data value ... #&gt; $ parts &lt;list&gt; [&lt;# A tibble: 3 x 4, id name ... #&gt; $ decisions &lt;list&gt; [&lt;# A tibble: 1 x 2, date decision ... "],
["pacote-lubridate-para-datas.html", "4.2 Pacote lubridate para datas", " 4.2 Pacote lubridate para datas library(lubridate) Originalmente, o R é ruim para trabalhar com datas, o que causa frustração e perda de tempo nas análises. O pacote lubridate foi criado para simplificar ao máximo a leitura de datas e extração de informações dessas datas. A função mais importante para leitura de dados no lubridate é a ymd. Essa função serve para ler qualquer data de uma string no formato YYYY-MM-DD. Essa função é útil pois funciona com qualquer separador entre os elementos da data e também porque temos uma função para cada formato (mdy, dmy, dym, myd, ydm). 4.2.1 Exercícios Leia January 20, 2018 com o lubridate. O que acontece se você rodar ymd(&quot;2017-02-29&quot;)? e ymd(&quot;2016-02-29&quot;)? Encontre um caso em que o lubridate não funciona como você gostaria. Outras funções importantes ymd_hms: lê datas e horários, generalizando ymd. year, month, day, quarter, weekday, week: extraem componentes da data. years, months, days: adicionam tempos a uma data, ajudando a criar vetores de datas. Por exemplo ymd(&#39;2015-01-01&#39;) + months(0:11) #&gt; [1] &quot;2015-01-01&quot; &quot;2015-02-01&quot; &quot;2015-03-01&quot; &quot;2015-04-01&quot; &quot;2015-05-01&quot; #&gt; [6] &quot;2015-06-01&quot; &quot;2015-07-01&quot; &quot;2015-08-01&quot; &quot;2015-09-01&quot; &quot;2015-10-01&quot; #&gt; [11] &quot;2015-11-01&quot; &quot;2015-12-01&quot; floor_date e ceiling_date: arredonda datas para uma unidade de interesse. Útil para agregar dados diários por semana, mês, trimestre etc. c(&quot;2017-04-10&quot;, &quot;2017-08-08&quot;, &quot;2017-02-28&quot;) %&gt;% ymd() %&gt;% floor_date(&quot;months&quot;) #&gt; [1] &quot;2017-04-01&quot; &quot;2017-08-01&quot; &quot;2017-02-01&quot; Outro exemplo: c(&quot;2017-04-10&quot;, &quot;2017-08-08&quot;, &quot;2017-02-28&quot;) %&gt;% ymd() %&gt;% ceiling_date(&quot;half year&quot;) #&gt; [1] &quot;2017-07-01&quot; &quot;2018-01-01&quot; &quot;2017-07-01&quot; Mais informações: ver a vignette do lubridate ver o cheatsheet. Blog: Comportamentos imprevisíveis do lubridate "],
["pacote-stringr-para-trabalhar-com-textos.html", "4.3 Pacote stringr para trabalhar com textos", " 4.3 Pacote stringr para trabalhar com textos O R básico não tem uma sintaxe consistente para trabalhar com textos. O pacote stringr ajuda a realizar todas as tarefas básicas de manipulação de texto, exigindo que o usuário estude apenas uma sintaxe. O stringr também é construído sobre a biblioteca ICU, implementada em C e C++, apresentando resultados rápidos e confiáveis. 4.3.1 Regras básicas As funções começam com str_. Caso esqueça o nome de uma função, basta digitar stringr::str_ e apertar TAB para ver quais são as opções. O primeiro argumento da função é sempre uma string. 4.3.2 Funções do stringr str_detect() retorna TRUE se a regex é compatível com a string e FALSE caso contrário. txt &lt;- c(&quot;acho que sim&quot;, &quot;acho que não&quot;) str_detect(txt, &quot;que&quot;) #&gt; [1] TRUE TRUE str_detect(txt, &quot;sim&quot;) #&gt; [1] TRUE FALSE str_lengh() retorna o comprimento de uma string. str_length(&#39;decisão favorável&#39;) #&gt; [1] 17 str_trim() retira espaços e quebras de linha/tabs no início ou final de string. string &lt;- &#39;\\n essa string é muito suja \\n&#39; c(string, str_trim(string)) #&gt; [1] &quot;\\n essa string é muito suja \\n&quot; #&gt; [2] &quot;essa string é muito suja&quot; str_replace() e str_replace_all() substituem um padrão (ou todos) encontrado para um outro padrão string &lt;- &#39;Recurso parcialmente parcialmente procedente&#39; str_replace(string, &#39;parcialmente &#39;, &#39;&#39;) #&gt; [1] &quot;Recurso parcialmente procedente&quot; str_replace_all(string, &#39;parcialmente &#39;, &#39;x &#39;) #&gt; [1] &quot;Recurso x x procedente&quot; str_replace(string, &#39;(parcialmente )+&#39;, &#39;x &#39;) #&gt; [1] &quot;Recurso x procedente&quot; str_replace_all(&#39;string com muitos espaços&#39;, &#39; +&#39;, &#39; &#39;) # tirar espaços extras #&gt; [1] &quot;string com muitos espaços&quot; str_match() e str_match_all() extrai pedaços da string identificados pela regex. Caso queira extrair somente a parte identificada, use parênteses. frases &lt;- c(&#39;a roupa do rei&#39;, &#39;de roma&#39;, &#39;o rato roeu&#39;) str_match(frases, &#39;roe&#39;) #&gt; [,1] #&gt; [1,] NA #&gt; [2,] NA #&gt; [3,] &quot;roe&quot; str_match_all(frases, &#39;ro&#39;) #&gt; [[1]] #&gt; [,1] #&gt; [1,] &quot;ro&quot; #&gt; #&gt; [[2]] #&gt; [,1] #&gt; [1,] &quot;ro&quot; #&gt; #&gt; [[3]] #&gt; [,1] #&gt; [1,] &quot;ro&quot; str_match(frases, &#39;o (ro)&#39;) #&gt; [,1] [,2] #&gt; [1,] NA NA #&gt; [2,] NA NA #&gt; [3,] &quot;o ro&quot; &quot;ro&quot; str_split() separa uma string em várias de acordo com um separador. string &lt;- &#39;eu sei, usar virgulas, de forma, perfeita&#39; str_split(string, &#39;, &#39;) #&gt; [[1]] #&gt; [1] &quot;eu sei&quot; &quot;usar virgulas&quot; &quot;de forma&quot; &quot;perfeita&quot; str_split(string, &#39;, &#39;, simplify = TRUE) #&gt; [,1] [,2] [,3] [,4] #&gt; [1,] &quot;eu sei&quot; &quot;usar virgulas&quot; &quot;de forma&quot; &quot;perfeita&quot; # avançado: quebrar por um padrão, mas mantendo ele na string # look arounds str_split(string, &#39;(?&lt;=, )&#39;) #&gt; [[1]] #&gt; [1] &quot;eu sei, &quot; &quot;usar virgulas, &quot; &quot;de forma, &quot; &quot;perfeita&quot; str_sub() extrai uma parte da string de acordo com os índices. string &lt;- &#39;quero pegar só uma parte disso&#39; str_sub(string, 13, 14) #&gt; [1] &quot;só&quot; str_sub(string, -5, -1) # usar números negativos para voltar do final da string #&gt; [1] &quot;disso&quot; indices &lt;- str_locate(string, &#39;parte&#39;) indices #&gt; start end #&gt; [1,] 20 24 str_sub(string, indices) # pode ser útil usar com str_locate. #&gt; [1] &quot;parte&quot; str_subset() retorna somente as strings compatíveis com a regex. frases &lt;- c(&#39;a roupa do rei&#39;, &#39;de roma&#39;, &#39;o rato roeu&#39;) str_subset(frases, &#39;d[eo]&#39;) #&gt; [1] &quot;a roupa do rei&quot; &quot;de roma&quot; "],
["expressoes-regulares.html", "4.4 Expressões regulares", " 4.4 Expressões regulares Expressão regular ou regex é uma sequência concisa de caracteres que representa várias strings. Entender o básico de expressões regulares é indispensável para trabalhar com jurimetria. Vamos estudar expressões regulares através de exemplos e com a função str_view(). A tabela abaixo mostra a aplicação de seis regex a seis strings distintas. txt &lt;- c(&#39;ban&#39;, &#39;banana&#39;, &#39;abandonado&#39;, &#39;paraíba né&#39;, &#39;BANANA&#39;, &#39;ele levou ban&#39;) expressoes &lt;- list( &#39;ban&#39;, # reconhece tudo que tenha &quot;ban&quot;, mas não ignora case &#39;BAN&#39;, # reconhece tudo que tenha &quot;BAN&quot;, mas não ignora case &#39;ban$&#39;, # reconhece apenas o que termina exatamente em &quot;ban&quot; &#39;^ban&#39;, # reconhece apenas o que começa exatamente com &quot;ban&quot; &#39;ba ?n&#39; # reconhece tudo que tenha &quot;ban&quot;, com ou sem espaço entre o &quot;b&quot; e o &quot;a&quot; ) # Desafio: entender o código que gera essa tabela ;) list(txt = txt, regex = expressoes) %&gt;% cross_df() %&gt;% mutate(result = map2_lgl(txt, regex, str_detect), result = if_else(result, &quot;X&quot;, &quot;&quot;)) %&gt;% distinct() %&gt;% spread(txt, result) %&gt;% knitr::kable() regex abandonado ban banana BANANA ele levou ban paraíba né ^ban X X ba ?n X X X X X ban X X X X BAN X ban$ X X 4.4.1 Quantificadores Os caracteres +, * e {x,y} indicam quantas vezes um padrão se repete: ey+ significa e e depois y “uma vez ou mais”. Por exemplo, reconhece hey, heyy, a eyyy, mas não reconhece e, y nem yy. ey* significa “zero vezes ou mais”. Por exemplo, reconhece hey, heyy, a eyyy e e, mas não reconhece y nem yy. ey{3} significa “exatamente três vezes”. Por exemplo, reconhece eyyy e eyyyy, mas não reconhece eyy. ey{1,3} significa “entre uma e três vezes”. Para aplicar um quantificador a um conjunto de caracteres, use parênteses. Por exemplo, (ey )+ reconhece ey ey. 4.4.2 Conjuntos Colocando caracteres dentro de [], reconhecemos quaisquer caracteres desse conjunto. Alguns exemplos práticos: [Cc]asa para reconhecer “casa” em maiúsculo ou minúsculo. [0-9] para reconhecer somente números. O mesmo vale para letras [a-z], [A-Z], [a-zA-Z] etc. O símbolo ^ dentro do colchete significa negação. Por exemplo, [^0-9] significa pegar tudo o que não é número. O símbolo . fora do colchete indica “qualquer caractere”, mas dentro do colchete é apenas ponto. Use [[:space:]]+ para reconhecer espaços e [[:punct:]]+ para reconhecer pontuações. 4.4.3 Miscelânea Use | para opções, por exemplo desfavor|desprov reconhece tanto “desfavorável” quanto “desprovido” \\n pula linha, \\f é final da página, \\t é tab. Use \\ para transformar caracteres especiais em literais. str_to_lower() e str_to_upper() para mudar o case de uma string. A lista de possibilidades com expressões regulares é extensa. Um bom lugar para testar o funcionamento de expressões regulares é o regex101. 4.4.4 Outros links Cheatsheet do stringr Apresentação do Caio Lente "],
["exemplo-decisoes-das-camaras.html", "4.5 Exemplo: decisões das câmaras", " 4.5 Exemplo: decisões das câmaras Suponha que temos o seguinte vetor de textos de decisões: d_decisoes &lt;- readRDS(glue(&#39;{path}/d_decisoes.rds&#39;)) negaram &lt;- regex(&#39;negaram&#39;, ignore_case = TRUE) parcial &lt;- regex(&#39;parcial&#39;, ignore_case = TRUE) deram &lt;- regex(&#39;deram&#39;, ignore_case = TRUE) tipos_decisao &lt;- function(decisoes) { case_when( str_detect(decisoes, negaram) ~ &#39;negado&#39;, str_detect(decisoes, parcial) ~ &#39;parcial&#39;, str_detect(decisoes, deram) ~ &#39;provido&#39;, TRUE ~ &quot;outros&quot;) } tipo_decisao &lt;- tipos_decisao(d_decisoes$decision) table(tipo_decisao) #&gt; tipo_decisao #&gt; negado outros parcial provido #&gt; 2638 191 1726 321 Exercício melhore essa classificação. Dica: é importante avaliar os casos que as expressões regulares não capturaram, para verficar se deixamos algo de fora. str_trunc(d_decisoes$decision[tipo_decisao == &quot;outros&quot;], 60) %&gt;% head(10) #&gt; [1] &quot;Em sede de juízo de retratação (artigo 1030, inciso II, d...&quot; #&gt; [2] &quot;Reconheceram, de ofício, a nulidade da sentença por ausên...&quot; #&gt; [3] &quot;de ofício julgaram extinta a punibilidade de Rui Devanir ...&quot; #&gt; [4] &quot;Nos termos do artigo 107, inciso I, do Código Penal, decl...&quot; #&gt; [5] &quot;MANTIVERAM o regime inicial semiaberto fixado no v. acórd...&quot; #&gt; [6] &quot;Julgaram extinta a punibilidade da acusada, pela ocorrênc...&quot; #&gt; [7] &quot;De ofício, JULGARAM EXTINTA a pretensão punitiva estatal ...&quot; #&gt; [8] &quot;Julgaram extinta a punibilidade, pela prescrição da prete...&quot; #&gt; [9] &quot;Declararam EXTINTA A PUNIBILIDADE pela prescrição da pret...&quot; #&gt; [10] &quot;DECLARARAM EXTINTA A PUNIBILIDADE de GUILHERME MARQUINE D...&quot; Mas como é que d_decisoes foi obtido de d_cposg? Para saber isso, precisaremos aprimorar nossos conhecimentos obtidos de lubridate e stringr, completando com o melhor toolkit de transformação de dados de todos os tempos: dplyr e seus amigos. "],
["pacotes-dplyr-e-tidyr.html", "4.6 Pacotes dplyr e tidyr", " 4.6 Pacotes dplyr e tidyr Vamos trabalhar com d_cjsg! 4.6.1 Características do dplyr O input é sempre uma tibble, e o output é sempre um tibble. No primeiro argumento colocamos o tibble, e nos outros argumentos colocamo o que queremos fazer. A utilização é facilitada com o emprego do operador %&gt;% 4.6.2 As cinco funções principais filter mutate select arrange summarise 4.6.3 select Utilizar starts_with(x), contains(x), matches(x), one_of(x), etc. Possível colocar nomes, índices, e intervalos de variáveis com :. d_cjsg %&gt;% select(id_lawsuit, id_decision, district, rapporteur) d_cjsg %&gt;% select(id_decision:district, class_subject) d_cjsg %&gt;% select(id_lawsuit, starts_with(&#39;dt_&#39;)) Exercícios: selecione as colunas que acabam com “ion” ou que contêm “sum”. tire as colunas de texto. 4.6.4 filter Use | para “ou”. Condições separadas por vírgulas é o mesmo que separar por &amp;. d_cjsg %&gt;% select(id_lawsuit, id_decision, district, rapporteur) %&gt;% filter(district == &#39;São Paulo&#39;) Dica: usar %in% d_cjsg %&gt;% select(id_lawsuit, id_decision, district, dt_decision, rapporteur) %&gt;% filter(district %in% c(&#39;Campinas&#39;, &#39;Sorocaba&#39;) &amp; (day(dmy(dt_decision)) &gt;= 29 | day(dmy(dt_decision)) &lt; 25)) d_cjsg %&gt;% select(rapporteur) %&gt;% filter(str_detect(rapporteur, &#39;[zZ]&#39;)) %&gt;% count(rapporteur, sort = TRUE) Exercícios: filtre todas as decisões de 2018. filtre apenas casos em que id_decision não é NA A aplicação de filter modifica o objeto d_cjsg? 4.6.5 mutate Aceita várias novas colunas iterativamente. Novas variáveis devem ter o mesmo length que o nrow do bd original ou 1. d_cjsg %&gt;% select(id_lawsuit, dt_decision) %&gt;% mutate(ano_julgamento = year(dmy(dt_decision)), ano_proc = str_sub(id_lawsuit, 12, 15), ano_proc = as.numeric(ano_proc), tempo_anos = ano_julgamento - ano_proc) Exercícios Crie uma coluna comarca_limpa com a comarca sem acentos e maiúscula Crie uma coluna binária drogas que vale TRUE se no texto da decisão algo é falado de drogas e FALSE caso contrário. Considere tanto a palavra droga como seus sinônimos, algum exemplo de droga e a Lei de Drogas. 4.6.6 arrange Simplesmente ordena de acordo com as opções. Utilizar desc para ordem decrescente. d_cjsg %&gt;% select(id_lawsuit, dt_decision) %&gt;% mutate(ano_julgamento = year(dmy(dt_decision)), ano_proc = str_sub(id_lawsuit, 12, 15), ano_proc = as.numeric(ano_proc)) %&gt;% mutate(tempo_anos = ano_julgamento - ano_proc) %&gt;% arrange(desc(tempo_anos)) 4.6.7 summarise Retorna um vetor de tamanho 1 a partir de uma conta com as variáveis. Geralmente é utilizado em conjunto com group_by. Algumas funções importantes: n(), n_distinct(). d_cjsg %&gt;% select(id_lawsuit, district, dt_decision, court) %&gt;% mutate(ano_julgamento = year(dmy(dt_decision)), ano_proc = str_sub(id_lawsuit, 12, 15), ano_proc = as.numeric(ano_proc)) %&gt;% mutate(tempo_anos = ano_julgamento - ano_proc) %&gt;% arrange(desc(tempo_anos)) %&gt;% group_by(district, court) %&gt;% summarise(n = n(), media_anos = mean(tempo_anos), min_anos = min(tempo_anos), max_anos = max(tempo_anos)) %&gt;% filter(n &gt; 5) %&gt;% arrange(desc(media_anos)) #&gt; # A tibble: 406 x 6 #&gt; # Groups: district [60] #&gt; district court n media_anos min_anos max_anos #&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Osasco 16ª Câmara de… 6 5.67 0 20.0 #&gt; 2 Tatuí 15ª Câmara de… 8 4.62 0 12.0 #&gt; 3 São Bernardo do Campo 3ª Câmara de … 8 4.38 0 28.0 #&gt; 4 Botucatu 16ª Câmara de… 10 4.10 0 15.0 #&gt; 5 Mogi das Cruzes 9ª Câmara de … 7 3.71 0 7.00 #&gt; 6 Tatuí 2ª Câmara de … 6 3.67 0 10.0 #&gt; 7 Avaré 13ª Câmara de… 8 3.62 0 11.0 #&gt; 8 Guarujá 5ª Câmara de … 6 3.50 0 10.0 #&gt; 9 Praia Grande 2ª Câmara de … 6 3.33 1.00 7.00 #&gt; 10 Mogi das Cruzes 4ª Câmara de … 6 3.00 0 7.00 #&gt; # ... with 396 more rows A função count() simplifica um group_by %&gt;% summarise %&gt;% ungroup e é bem útil: d_cjsg %&gt;% count(rapporteur, sort = TRUE) %&gt;% mutate(prop = n / sum(n), prop = scales::percent(prop)) Exercício Quem é o relator mais prolixo? 4.6.8 gather “Empilha” o banco de dados d_cjsg %&gt;% filter(!is.na(id_decision)) %&gt;% select(id_decision:dt_registration) %&gt;% gather(key, value, -id_decision) %&gt;% arrange(id_decision) 4.6.9 spread “Joga” uma variável nas colunas É essencialmente a função inversa de gather d_cjsg %&gt;% filter(!is.na(id_decision)) %&gt;% select(id_decision:dt_registration) %&gt;% gather(key, value, -id_decision) %&gt;% spread(key, value) 4.6.10 Funções auxiliares unite junta duas ou mais colunas usando algum separador (_, por exemplo). separate faz o inverso de unite, e uma coluna em várias usando um separador. d_cjsg %&gt;% select(id_lawsuit, class_subject) %&gt;% separate(class_subject, c(&#39;classe&#39;, &#39;assunto&#39;), sep = &#39; / &#39;, extra = &#39;merge&#39;, fill = &#39;right&#39;) %&gt;% count(assunto, sort = TRUE) 4.6.11 nest e unnest nest e unnest são operações inversas e servem para tratar dados complecos, como o que temos em d_cposg d_cposg &lt;- read_rds(glue(&quot;{path}/d_cposg.rds&quot;)) d_partes &lt;- d_cposg %&gt;% select(id_lawsuit, parts) %&gt;% unnest(parts) d_data &lt;- d_cposg %&gt;% select(id_lawsuit, data) %&gt;% unnest(data) 4.6.12 Um pouco mais de transformação de dados Para juntar tabelas, usar inner_join, left_join, anti_join, etc. Para realizar operações mais gerais, usar do. Para retirar duplicatas, utilizar distinct. Para fazer algumas mágicas, trabalhar com "],
["finalizando-analise-das-camaras.html", "4.7 Finalizando análise das câmaras", " 4.7 Finalizando análise das câmaras No exemplo das câmaras, vamos fazer três gráficos. O primeiro mostra a proporção de processos por assunto em cada câmara. d_cjsg %&gt;% # transformacao filter(!is.na(court)) %&gt;% separate(class_subject, c(&#39;classe&#39;, &#39;assunto&#39;), sep = &#39; / &#39;, extra = &#39;merge&#39;, fill = &#39;right&#39;) %&gt;% mutate(assunto = assunto %&gt;% str_wrap(19) %&gt;% fct_infreq() %&gt;% fct_rev() %&gt;% fct_lump(n = 11, other_level = &quot;Outros&quot;)) %&gt;% add_count(assunto) %&gt;% group_by(court, assunto) %&gt;% summarise(nn = n()) %&gt;% mutate(ntot = sum(nn), prop = nn / ntot) %&gt;% ungroup() %&gt;% mutate(num = parse_number(court), num = str_pad(num, 2, pad = &quot;0&quot;)) %&gt;% # grafico ggplot(aes(x = num, fill = assunto, y = prop)) + geom_col(colour = &#39;black&#39;, position = &quot;stack&quot;) + theme_minimal(14) + scale_y_continuous(labels = scales::percent) + labs(x = &#39;Órgão julgador&#39;, y = &#39;Proporção de \\nprocessos por assunto&#39;, fill = &quot;&quot;) + guides(fill = guide_legend(reverse = TRUE)) + theme(legend.position = &quot;bottom&quot;) O segundo mostra a proporção de decisões antes e depois da virada. # essa é a classificação final negaram &lt;- regex(&#39;negara?m|nega-se|negam-se&#39;, ignore_case = TRUE) parcial &lt;- regex(&#39;parcial&#39;, ignore_case = TRUE) deram &lt;- regex(&#39;deram|mantiv|dá-se&#39;, ignore_case = TRUE) extinto &lt;- regex(&#39;extin&#39;, ignore_case = TRUE) nulo &lt;- regex(&#39;nul&#39;, ignore_case = TRUE) nconhec &lt;- regex(&#39;conhec&#39;, ignore_case = TRUE) tipos_decisao &lt;- function(decisoes) { case_when( str_detect(decisoes, negaram) ~ &#39;negado&#39;, str_detect(decisoes, parcial) ~ &#39;parcial&#39;, str_detect(decisoes, deram) ~ &#39;provido&#39;, str_detect(decisoes, extinto) ~ &#39;extinto&#39;, str_detect(decisoes, nulo) ~ &#39;nulo&#39;, str_detect(decisoes, nconhec) ~ &#39;não conhecido&#39;, TRUE ~ &quot;outros&quot;) } partes_apelacoes &lt;- d_cposg %&gt;% select(id, id_lawsuit, parts) %&gt;% unnest(parts) %&gt;% filter(part == &#39;Apelado&#39;, str_detect(name, &#39;[Mm]inist&#39;)) %&gt;% distinct(id_lawsuit) d_decisoes &lt;- d_cposg %&gt;% select(id, id_lawsuit, decisions) %&gt;% unnest(decisions) %&gt;% semi_join(partes_apelacoes, &quot;id_lawsuit&quot;) %&gt;% arrange(desc(date)) %&gt;% group_by(id_lawsuit) %&gt;% slice(1) %&gt;% ungroup() # write_rds(d_decisoes, glue(&quot;{path}/d_decisoes.rds&quot;), compress = &quot;bz2&quot;) decisoes &lt;- d_decisoes %&gt;% mutate(tipo_decisao = tipos_decisao(decision)) %&gt;% select(id_lawsuit, tipo_decisao) decisoes_mes &lt;- d_cjsg %&gt;% inner_join(decisoes, &#39;id_lawsuit&#39;) %&gt;% mutate(data = dmy(dt_decision)) %&gt;% arrange(desc(data)) %&gt;% distinct(id_lawsuit, .keep_all = TRUE) %&gt;% mutate(mes = floor_date(data, &#39;month&#39;)) %&gt;% filter(mes &gt;= &quot;2017-12-01&quot;) decisoes_mes %&gt;% mutate(tipo_decisao = case_when( tipo_decisao == &quot;negado&quot; ~ &quot;Negado&quot;, tipo_decisao == &quot;provido&quot; ~ &quot;Provido&quot;, tipo_decisao == &quot;parcial&quot; ~ &quot;Parcialmente&quot;, TRUE ~ &quot;Outros&quot; )) %&gt;% group_by(mes, tipo_decisao) %&gt;% summarise(n = n()) %&gt;% mutate(prop = n / sum(n)) %&gt;% ungroup() %&gt;% complete(mes, tipo_decisao, fill = list(n = 0, prop = 0)) %&gt;% # grafico ggplot(aes(x = as.character(mes), y = prop, colour = tipo_decisao, group = tipo_decisao)) + geom_line() + geom_point(size = 3) + geom_text(aes(y = 0.65, label = n, colour = NULL, group = NULL), data = count(decisoes_mes, mes), size = 5) + scale_y_continuous(labels = scales::percent) + scale_x_discrete(labels = c(&quot;Dezembro/2017&quot;, &quot;Janeiro/2018&quot;)) + xlab(&#39;Mês&#39;) + ylab(&#39;Proporção de cada tipo de decisão&#39;) + theme_minimal(16) O terceiro mostra a proporção de cada tipo de decisão em cada câmara. d_cjsg %&gt;% filter(!is.na(court)) %&gt;% distinct(id_lawsuit, .keep_all = TRUE) %&gt;% inner_join(decisoes, &#39;id_lawsuit&#39;) %&gt;% group_by(court, tipo_decisao) %&gt;% summarise(n = n()) %&gt;% mutate(ntot = sum(n), prop = n / ntot) %&gt;% ungroup() %&gt;% filter(ntot &gt; 10) %&gt;% mutate(num = parse_number(court), num = str_pad(num, 2, pad = &quot;0&quot;)) %&gt;% complete(num, tipo_decisao, fill = list(n = 0, prop = 0)) %&gt;% arrange(tipo_decisao) %&gt;% mutate(num = fct_reorder(num, prop, fun = nth, n = 3, .desc = TRUE), tipo_decisao = fct_reorder(tipo_decisao, prop)) %&gt;% ggplot(aes(x = num, fill = tipo_decisao, y = prop)) + geom_bar(stat = &#39;identity&#39;, colour = &#39;black&#39;, position = &#39;stack&#39;) + scale_y_continuous(labels = scales::percent) + coord_flip() + theme_minimal(16) + theme(legend.position = &quot;bottom&quot;) + labs(x = &quot;Câmara&quot;, y = &#39;Proporção de processos por tipo de decisão&#39;, fill = &quot;Decisão&quot;) "],
["transformacao-de-dados-2.html", "Capítulo 5 Transformação de dados 2", " Capítulo 5 Transformação de dados 2 Até agora, estudamos as principais ferramentas de transformação de dados do tidyverse. Hoje vamos aumentar um pouco mais nosso toolkit e vamos utilizá-lo na prática nos exempos das câmaras e especialização. 5.0.1 Na última vez lubridate: dmy() &amp; friends. stringr: família str_*() um pouquinho de regex dplyr: 5 verbos select, filter, mutate, arrange, summarise 5.0.2 Setup Logar no servidor http://r.abj.org.br No projeto r4jurimetrics, aba git -&gt; Pull Abrir o arquivo 03-vectors.Rmd Rodar library(tidyverse) Ler as bases: d_cjsg &lt;- read_rds(glue(&quot;{path}/d_cjsg.rds&quot;)) d_cposg &lt;- read_rds(glue(&quot;{path}/d_cposg.rds&quot;)) Você, depois dessa aula Se você não praticar depois "],
["funcoes-do-tidyr.html", "5.1 Funções do tidyr", " 5.1 Funções do tidyr O dplyr está para o tidyr assim como tesoura/cola está para um alicate/martelo. Enquanto o dplyr faz recortes na base (com filter()e select()) e adições simples (mutate(), summarise()), o tidyr mexe no formato da tabela (gather(), spread()) e faz modificações menos triviais. 5.1.1 gather “Empilha” o banco de dados d_cjsg %&gt;% filter(!is.na(id_decision)) %&gt;% select(id_decision:dt_registration) %&gt;% gather(key, value, -id_decision) %&gt;% arrange(id_decision) 5.1.2 spread “Joga” uma variável nas colunas É essencialmente a função inversa de gather d_cjsg %&gt;% filter(!is.na(id_decision)) %&gt;% select(id_decision:dt_registration) %&gt;% gather(key, value, -id_decision) %&gt;% spread(key, value) 5.1.3 Unindo e separando colunas unite junta duas ou mais colunas usando algum separador (_, por exemplo). separate faz o inverso de unite, e uma coluna em várias usando um separador. d_cjsg %&gt;% select(id_lawsuit, class_subject) %&gt;% separate(class_subject, c(&#39;classe&#39;, &#39;assunto&#39;), sep = &#39; / &#39;, extra = &#39;merge&#39;, fill = &#39;right&#39;) %&gt;% count(assunto, sort = TRUE) 5.1.4 List columns: nest e unnest nest e unnest são operações inversas e servem para tratar dados complecos, como o que temos em d_cposg d_partes &lt;- d_cposg %&gt;% select(id_lawsuit, parts) %&gt;% unnest(parts) d_data &lt;- d_cposg %&gt;% select(id_lawsuit, data) %&gt;% unnest(data) 5.1.5 Joins Para juntar tabelas, usar inner_join, left_join, anti_join, etc. O melhor material disso está em http://r4ds.had.co.nz/relational-data.html. Exemplo de inner join: d_cjsg %&gt;% filter(dmy(dt_registration) == &quot;2018-01-18&quot;, !is.na(id_decision)) %&gt;% select(id_decision, id_lawsuit) %&gt;% inner_join(d_cposg, &quot;id_lawsuit&quot;) %&gt;% glimpse() #&gt; Observations: 170 #&gt; Variables: 8 #&gt; $ id_decision &lt;chr&gt; &quot;11109089&quot;, &quot;11109088&quot;, &quot;11108246&quot;, &quot;11108245&quot;, &quot;1... #&gt; $ id_lawsuit &lt;chr&gt; &quot;0003779-93.2015.8.26.0597&quot;, &quot;3001293-25.2013.8.26... #&gt; $ id &lt;chr&gt; &quot;00037799320158260597&quot;, &quot;30012932520138260510&quot;, &quot;0... #&gt; $ file &lt;chr&gt; &quot;data-raw/camaras/cposg/00037799320158260597.html&quot;... #&gt; $ hidden &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, F... #&gt; $ data &lt;list&gt; [&lt;# A tibble: 14 x 2, data value ... #&gt; $ parts &lt;list&gt; [&lt;# A tibble: 3 x 4, id name ... #&gt; $ decisions &lt;list&gt; [&lt;# A tibble: 1 x 2, date decision ... Exemplo de right join: d_cjsg %&gt;% filter(dmy(dt_registration) == &quot;2018-01-18&quot;, !is.na(id_decision)) %&gt;% select(id_decision, id_lawsuit) %&gt;% right_join(d_cposg, &quot;id_lawsuit&quot;) %&gt;% glimpse() #&gt; Observations: 11,763 #&gt; Variables: 8 #&gt; $ id_decision &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA... #&gt; $ id_lawsuit &lt;chr&gt; &quot;0000003-71.2016.8.26.0073&quot;, &quot;0000004-09.2017.8.26... #&gt; $ id &lt;chr&gt; &quot;00000037120168260073&quot;, &quot;00000040920178260142&quot;, &quot;0... #&gt; $ file &lt;chr&gt; &quot;data-raw/camaras/cposg/00000037120168260073.html&quot;... #&gt; $ hidden &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, F... #&gt; $ data &lt;list&gt; [&lt;# A tibble: 11 x 2, data value ... #&gt; $ parts &lt;list&gt; [&lt;# A tibble: 3 x 4, id name ... #&gt; $ decisions &lt;list&gt; [&lt;# A tibble: 1 x 2, date decision ... 5.1.6 Duplicatas Para retirar duplicatas, utilizar distinct. Ele considera apenas a primeira linha em que encontra um padrão para as combinações de variáveis escolhidas e descarta as demais. d_cjsg %&gt;% distinct(district) Para manter as demais colunas, use .keep_all =: d_cjsg %&gt;% distinct(district, .keep_all = TRUE) Use janitor::get_dupes() para averiguar os casos em que há repetição de combinações de colunas. d_cjsg %&gt;% janitor::get_dupes(id_lawsuit) Para mais aplicações do janitor, ver este blog post. "],
["finalizando-analise-das-camaras-1.html", "5.2 Finalizando análise das câmaras", " 5.2 Finalizando análise das câmaras Agora vamos fazer gráficos! 5.2.1 Como se distribuem os assuntos em cada câmara? Gráfico fraqueza: d_cjsg %&gt;% separate(class_subject, c(&#39;classe&#39;, &#39;assunto&#39;), sep = &#39; / &#39;, extra = &#39;merge&#39;, fill = &#39;right&#39;) %&gt;% ggplot(aes(x = court, fill = assunto)) + geom_bar(colour = &#39;black&#39;, position = &quot;fill&quot;, show.legend = FALSE) Gráfico bacana: d_cjsg %&gt;% ## transformacao ------------------------------------------------------------- # tirar NA (não tem problema pois são aqueles casos que não existem) filter(!is.na(court)) %&gt;% separate(class_subject, c(&#39;classe&#39;, &#39;assunto&#39;), sep = &#39; / &#39;, extra = &#39;merge&#39;, fill = &#39;right&#39;) %&gt;% # categorizar os assuntos e mudar a ordem mutate(assunto = assunto %&gt;% str_wrap(19) %&gt;% fct_infreq() %&gt;% # ordena o factor decrescente fct_rev() %&gt;% fct_lump(n = 11, other_level = &quot;Outros&quot;)) %&gt;% # pega somente os números das câmaras e coloca zeros à esquerda mutate(num = parse_number(court), num = str_pad(num, 2, pad = &quot;0&quot;)) %&gt;% # grafico -------------------------------------------------------------------- ggplot(aes(x = num, fill = assunto)) + geom_bar(colour = &#39;black&#39;, position = &quot;fill&quot;) + guides(fill = guide_legend(reverse = TRUE)) + # coisas cosméticas theme_minimal(14) + scale_y_continuous(labels = scales::percent) + labs(x = &#39;Órgão julgador&#39;, y = &#39;Proporção de \\nprocessos por assunto&#39;, fill = &quot;&quot;) + theme(legend.position = &quot;bottom&quot;) 5.2.2 Quantas decisões proferidas por semana? O segundo mostra a proporção de decisões antes e depois da virada do ano. Primeiro, vamos montar a função que classifica as decisões (da aula passada) # essa é a classificação final negaram &lt;- regex(&#39;negara?m|nega-se|negam-se&#39;, ignore_case = TRUE) parcial &lt;- regex(&#39;parcial&#39;, ignore_case = TRUE) deram &lt;- regex(&#39;deram|mantiv|dá-se|nul|conhec&#39;, ignore_case = TRUE) extinto &lt;- regex(&#39;extin&#39;, ignore_case = TRUE) tipos_decisao &lt;- function(decisoes) { case_when( str_detect(decisoes, negaram) ~ &#39;negado&#39;, str_detect(decisoes, parcial) ~ &#39;parcial&#39;, str_detect(decisoes, deram) ~ &#39;provido&#39;, str_detect(decisoes, extinto) ~ &#39;extinto&#39;, TRUE ~ &quot;outros&quot;) } Agora, vamos pegar apenas os casos em que as pessoas entraram com recursos de apelação contra o Ministério Público. partes_apelacoes &lt;- d_cposg %&gt;% select(id, id_lawsuit, parts) %&gt;% unnest(parts) %&gt;% filter(part == &#39;Apelado&#39;, str_detect(name, &#39;[Mm]inist&#39;)) %&gt;% # Exercício: por que usamos distinct aqui? distinct(id_lawsuit) Agora, montamos a base de decisões d_decisoes &lt;- d_cposg %&gt;% select(id, id_lawsuit, decisions) %&gt;% unnest(decisions) %&gt;% # Exercício: o que faz semi_join()? semi_join(partes_apelacoes, &quot;id_lawsuit&quot;) %&gt;% arrange(desc(date)) %&gt;% group_by(id_lawsuit) %&gt;% # Exercício: o que faz slice()? slice(1) %&gt;% ungroup() # write_rds(d_decisoes, glue(&quot;{path}/d_decisoes.rds&quot;), compress = &quot;bz2&quot;) decisoes &lt;- d_decisoes %&gt;% mutate(tipo_decisao = tipos_decisao(decision)) %&gt;% select(id_lawsuit, tipo_decisao) Agora vamos juntar d_cjsg com a base de decisoes para fazer o gráfico. decisoes_semana &lt;- d_cjsg %&gt;% inner_join(decisoes, &#39;id_lawsuit&#39;) %&gt;% mutate(data = dmy(dt_registration)) %&gt;% arrange(desc(data)) %&gt;% distinct(id_lawsuit, .keep_all = TRUE) %&gt;% mutate(semana = floor_date(data, &#39;week&#39;)) %&gt;% # o que faz between()? filter(between(semana, as.Date(&quot;2017-10-01&quot;), as.Date(&quot;2018-01-18&quot;))) Gráfico fraqueza: decisoes_semana %&gt;% count(semana, tipo_decisao) %&gt;% ggplot(aes(x = semana, y = n, colour = tipo_decisao)) + geom_line() Exercício: Qual o problema principal desse gráfico? Para resolver esse problema, podemos utilizar a função complete() decisoes_semana %&gt;% count(semana, tipo_decisao) %&gt;% complete(semana, tipo_decisao) Mas ainda temos datas em que não houve nenhuma decisão! Para resolver isso, precisamos de full_seq() decisoes_semana %&gt;% count(semana, tipo_decisao) %&gt;% complete(semana = full_seq(semana, 7), tipo_decisao, fill = list(n = 0)) Gráfico bacana: decisoes_semana %&gt;% # mudar ordem mutate(tipo_decisao = fct_infreq(tipo_decisao)) %&gt;% count(semana, tipo_decisao) %&gt;% # completar com zeros complete(semana = full_seq(semana, 7), tipo_decisao, fill = list(n = 0)) %&gt;% # gráfico ggplot(aes(x = semana, y = n, colour = tipo_decisao)) + geom_line() + # perfumaria labs(x = &quot;Semana&quot;, y = &quot;Quantidade de decisões&quot;, colour = &quot;Decisão&quot;) + scale_x_date(breaks = scales::date_breaks(&quot;1 week&quot;), labels = scales::date_format(&quot;%b %d&quot;)) + theme_minimal(16) 5.2.3 Qual a proporção de decisões por câmara? Gráfico fraqueza: d_cjsg %&gt;% distinct(id_lawsuit, .keep_all = TRUE) %&gt;% inner_join(decisoes, &#39;id_lawsuit&#39;) %&gt;% ggplot(aes(x = court, fill = tipo_decisao)) + geom_bar(position = &quot;fill&quot;) Gráfico bacana: prop_negados &lt;- function(x) { sum(x == &quot;negado&quot;) / length(x) } d_cjsg %&gt;% distinct(id_lawsuit, .keep_all = TRUE) %&gt;% inner_join(decisoes, &#39;id_lawsuit&#39;) %&gt;% mutate(num = court %&gt;% parse_number() %&gt;% str_pad(width = 2, pad = &quot;0&quot;) %&gt;% fct_reorder(tipo_decisao, prop_negados) %&gt;% fct_rev()) %&gt;% mutate(tipo_decisao = fct_infreq(tipo_decisao) %&gt;% fct_rev()) %&gt;% # grafico ggplot(aes(x = num, fill = tipo_decisao)) + geom_bar(colour = &#39;black&#39;, position = &#39;fill&#39;, size = .3) + geom_hline(yintercept = 1:4 / 4, linetype = 2, alpha = .4) + scale_y_continuous(labels = scales::percent) + coord_flip() + # perfumaria guides(fill = guide_legend(reverse = TRUE)) + theme_minimal(16) + theme(legend.position = &quot;bottom&quot;) + labs(x = &quot;Câmara&quot;, y = &#39;Proporção de processos por tipo de decisão&#39;, fill = &quot;Decisão&quot;) "],
["purrr.html", "5.3 purrr", " 5.3 purrr Ao usar programação funcional (PF) podemos criar códigos concisos e “pipeáveis”, que tornam o código mais legível e o processo de debug mais simples. Além disso, códigos funcionais geralmente são paralelizáveis, permitindo que tratemos problemas grandes com poucas modificações. Apesar de o R base já ter funções que podem ser consideradas elementos de PF, a implementação destas não é elegante. Este tutorial abordará a implementação de PF realizada pelo pacote purrr. Cuidado: material altamente viciante. 5.3.1 Iterações básicas As funções map() são quase como substitutas para laços for: elas abstraem a iteração em apenas uma linha. Veja esse exemplo de laço usando for: soma_um &lt;- function(x) x + 1 obj &lt;- 10:15 for (i in seq_along(obj)) { obj[i] &lt;- soma_um(obj[i]) } obj #&gt; [1] 11 12 13 14 15 16 O que de fato estamos tentando fazer com o laço acima? Temos um vetor (obj) e queremos aplicar uma função (soma_um()) em cada elemento dele. A função map() remove a necessidade de declaramos um objeto iterador auxiliar (i) e simplesmente aplica a função desejada em cada elemento do objeto dado. soma_um &lt;- function(x) x + 1 obj &lt;- 10:15 obj &lt;- map(obj, soma_um) obj #&gt; [[1]] #&gt; [1] 11 #&gt; #&gt; [[2]] #&gt; [1] 12 #&gt; #&gt; [[3]] #&gt; [1] 13 #&gt; #&gt; [[4]] #&gt; [1] 14 #&gt; #&gt; [[5]] #&gt; [1] 15 #&gt; #&gt; [[6]] #&gt; [1] 16 5.3.1.1 Achatando resultados Se quisermos “achatar” o resultado, devemos informar qual será o seu tipo. Isso pode ser feito com as irmãs da map(): map_chr() (para strings), map_dbl() (para números reais), map_int() (para números inteiros) e map_lgl() (para booleanos). obj &lt;- 10:15 map_dbl(obj, soma_um) #&gt; [1] 11 12 13 14 15 16 O purrr também nos fornece outra ferramenta interessante para achatar listas: a família flatten(). map_chr() é um atalho para map() %&gt;% flatten_chr(). O achatamento não precisa necessariamente virar um atômico. Duas funções muito utilizadas da família map() são map_dfc() e map_dfr(), que equivalem a um map() seguido de um dplyr::bind_cols() ou de um dplyr::bind_rows() respectivamente. walk() é uma versão do map() que não retorna nada nas iterações. Ela serve para fazer efeitos colaterais, como salvar arquivos e imprimir coisas na tela. map(1:2, print) #&gt; [1] 1 #&gt; [1] 2 #&gt; [[1]] #&gt; [1] 1 #&gt; #&gt; [[2]] #&gt; [1] 2 walk(1:2, print) #&gt; [1] 1 #&gt; [1] 2 5.3.1.2 Fórmulas e reticências Algo bastante útil da família map() é a possibilidade de passar argumentos fixos para a função que será aplicada. A primeira forma de fazer isso envolve fórmulas: soma_n &lt;- function(x, n = 1) x + n obj &lt;- 10:15 map_dbl(obj, ~soma_n(.x, 2)) #&gt; [1] 12 13 14 15 16 17 Precisamos colocar um til (~) antes da função que será chamada. Feito isso, podemos utilizar o placeholder .x para indicar onde deve ser colocado cada elemento de obj. A outra forma de passar argumentos para a função é através das reticências de map(). Desta maneira precisamos apenas dar o nome do argumento e seu valor logo após a função soma_n(). soma_n &lt;- function(x, n = 1) x + n obj &lt;- 10:15 map_dbl(obj, soma_n, n = 2) #&gt; [1] 12 13 14 15 16 17 5.3.2 Iterações intermediárias Agora que já exploramos os básicos da família map() podemos partir para iterações um pouco mais complexas. Observe o laço a seguir: soma_ambos &lt;- function(x, y) x + y obj_1 &lt;- 10:15 obj_2 &lt;- 20:25 for (i in seq_along(obj_1)) { obj_1[i] &lt;- soma_ambos(obj_1[i], obj_2[i]) } obj_1 #&gt; [1] 30 32 34 36 38 40 Com a função map2() podemos reproduzir o laço acima em apenas uma linha. Ela abstrai a iteração em paralelo, aplica a função em cada par de elementos das entradas e, assim como sua prima map(), pode achatar o objeto retornado com os sufixos _chr, _dbl, _int e _lgl. soma_ambos &lt;- function(x, y) x + y obj_1 &lt;- 10:15 obj_2 &lt;- 20:25 obj_1 &lt;- map2_dbl(obj_1, obj_2, soma_ambos) obj_1 #&gt; [1] 30 32 34 36 38 40 Como o pacote purrr é extremamente consistente, a map2() também funciona com reticências e fórmulas. Poderíamos, por exemplo, transformar soma_ambos() em uma função anônima: obj_1 &lt;- 10:15 obj_2 &lt;- 20:25 map2_dbl(obj_1, obj_2, ~.x + .y) #&gt; [1] 30 32 34 36 38 40 Desta vez também temos acesso ao placeholder .y para indicar onde os elementos de do segundo vetor devem ir. 5.3.2.1 Generalização Para não precisar oferecer uma função para cada número de argumentos, o pacote purrr fornece a pmap(). Para essa função devemos passar uma lista em que cada elemento é um dos objetos a ser iterado: soma_varios &lt;- function(x, y, z) x + y + z obj_1 &lt;- 10:15 obj_2 &lt;- 20:25 obj_3 &lt;- 30:35 obj_1 &lt;- pmap_dbl(list(obj_1, obj_2, obj_3), soma_varios) obj_1 #&gt; [1] 60 63 66 69 72 75 Com a pmap() não podemos usar fórmulas. Se quisermos usar uma função anônima com ela, precisamos declará-la a função no seu corpo: obj_1 &lt;- 10:15 obj_2 &lt;- 20:25 obj_3 &lt;- 30:35 pmap_dbl(list(obj_1, obj_2, obj_3), function(x, y, z) { x + y + z }) #&gt; [1] 60 63 66 69 72 75 5.3.2.2 Iterando em índices imap() é um atalho para map2(x, names(x), ...) quando x tem nomes e para map2(x, seq_along(x), ...) caso contrário: obj &lt;- 10:15 imap_chr(obj, ~paste(.x, .y, sep = &quot;/&quot;)) #&gt; [1] &quot;10/1&quot; &quot;11/2&quot; &quot;12/3&quot; &quot;13/4&quot; &quot;14/5&quot; &quot;15/6&quot; Naturalmente, assim como toda a família map(), a imap() também funciona com os sufixos de achatamento. 5.3.3 Iterações avançadas Agora vamos passar para os tipos mais obscuros de laços. Cada item desta seção será mais denso do que os das passadas, por isso encorajamos todos os leitores para que também leiam a documentação de cada função aqui abordada. 5.3.3.1 Iterações com condicionais Imagine que precisamos aplicar uma função somente em alguns elementos de um vetor. Veja o trecho de código a seguir por exemplo: dobra &lt;- function(x) x * 2 obj &lt;- 10:15 for (i in seq_along(obj)) { if (obj[i] %% 2 == 1) { obj[i] &lt;- dobra(obj[i]) } else { obj[i] &lt;- obj[i] } } obj #&gt; [1] 10 22 12 26 14 30 Aplicamos a função dobra() apenas nos elementos ímpares do vetor obj. Com o pacote purrr temos duas maneiras de fazer isso: com map_if() ou map_at(). A primeira dessas funções aplica a função dada apenas quando um predicado é TRUE. Esse predicado pode ser uma função ou uma fórmula. eh_impar &lt;- function(x) x %% 2 == 1 dobra &lt;- function(x) x * 2 obj &lt;- 10:15 map_if(obj, eh_impar, dobra) %&gt;% flatten_dbl() #&gt; [1] 10 22 12 26 14 30 Com fórmulas poderíamos eliminar completamente a necessidade de funções declaradas: obj &lt;- 10:15 map_if(obj, ~.x %% 2 == 1, ~.x * 2) %&gt;% flatten_dbl() #&gt; [1] 10 22 12 26 14 30 Para map_at() devemos passar um vetor de nomes ou índices onde a função deve ser aplicada: obj &lt;- 10:15 map_at(obj, c(2, 4, 6), ~.x * 2) %&gt;% flatten_dbl() #&gt; [1] 10 22 12 26 14 30 5.3.4 Redução e acúmulo Outras funções simbólicas de programação funcional além da map() são reduce() e accumulate(), que aplicam transformações em valores acumulados. Observe o laço a seguir: soma_ambos &lt;- function(x, y) x + y obj &lt;- 10:15 for (i in 2:length(obj)) { obj[i] &lt;- soma_ambos(obj[i-1], obj[i]) } obj #&gt; [1] 10 21 33 46 60 75 Observe como isso ficaria usando accumulate() soma_ambos &lt;- function(x, y) { x + y } obj &lt;- 10:15 accumulate(obj, soma_ambos) #&gt; [1] 10 21 33 46 60 75 accumulate(obj, ~.x + .y) #&gt; [1] 10 21 33 46 60 75 Obs.: Aqui, .x é o valor acumulado e .y é o valor “atual” do objeto sendo iterado. Se não quisermos o valor acumulado em cada passo da iteração, podemos usar reduce(): obj &lt;- 10:15 reduce(obj, ~.x+.y) #&gt; [1] 75 Para a nossa comodidade, essas duas funções também têm variedades paralelas (accumulate2() e reduce2()), assim como variedades invertidas accumulate_right() e reduce_right()). 5.3.5 Miscelânea 5.3.5.1 Transposição e indexação profunda Quando precisarmos lidar com listas complexas e profundas, o purrr nos fornece duas funções extremamente úteis: transpose() e pluck(). A primeira transpõe uma lista, enquanto a segunda é capaz de acessar elementos profundos de uma lista sem a necessidade de colchetes. obj &lt;- list( list(a = 1, b = 2, c = 3), list(a = 4, b = 5, c = 6) ) pluck(obj, 2, &quot;b&quot;) #&gt; [1] 5 str(transpose(obj)) #&gt; List of 3 #&gt; $ a:List of 2 #&gt; ..$ : num 1 #&gt; ..$ : num 4 #&gt; $ b:List of 2 #&gt; ..$ : num 2 #&gt; ..$ : num 5 #&gt; $ c:List of 2 #&gt; ..$ : num 3 #&gt; ..$ : num 6 Obs.: Se você estiver com muitos problemas com listas profundas, dê uma olhada nas funções relacionadas a depth() pois elas podem ser muito úteis. 5.3.5.2 Aplicação parcial Se quisermos pré-preencher os argumentos de uma função (seja para usá-la em uma pipeline ou com alguma função do próprio purrr), temos partial(). soma_varios &lt;- function(x, y, z) x + y + z nova_soma &lt;- partial(soma_varios, x = 1, y = 2) nova_soma(3) #&gt; [1] 6 5.3.5.3 Execução segura Usar tryCatch() e try() no R sempre foi uma dor de cabeça enorme. O purrr resolve esse problema de maneira elegante e eficaz. quietly() retorna uma lista com resultado, saída, mensagem e alertas, safely() retorna uma lista com resultado e erro (um destes sempre é NULL), e possibly() silencia o erro e retorna um valor dado pelo usuário. soma_um &lt;- function(x) { x + 1 } s_soma_um &lt;- safely(soma_um, 0) obj &lt;- c(10, 11, &quot;a&quot;, 13, 14, 15) s_soma_um(obj) #&gt; $result #&gt; [1] 0 #&gt; #&gt; $error #&gt; &lt;simpleError in x + 1: non-numeric argument to binary operator&gt; É interessante notar que essas funções são advérbios, pois modificam as funções principais, que geralmente são verbos. Se quiser ler mais sobre chamadas seguras, veja o texto desse blog "],
["exemplo-formatando-arquivos.html", "5.4 Exemplo: formatando arquivos", " 5.4 Exemplo: formatando arquivos Vamos agora utilizar o purrr em conjunto com as outras ferramentas do tidyverse para trabalhar o projeto da especialização. Nosso input de dados nesse projeto foi uma planilha enviada pela Corregedoria do TJSP, contendo três abas: infos, partes e movimentações, cada uma delas com suas respectivas colunas. Cada tabela correspondia a um ano: 2013, 2014 ou 2015. Ao ler esses arquivos, nosso input era uma lista com três elementos, para cada ano: d_infos, d_movs e d_partes. Cada um desses elementos é uma tibble. Para exemplificar, montamos algumas tabelas de exemplo, com apenas 1000 processos por ano. Elas estão em data-raw/espec Exercício: o que faz esse código? Dica: leia o arquivo data-raw/espec/d_2014.rds, guarde num objeto d_2014 e use o elemento d_2014$d_movs nessa função. nest_infos &lt;- function(.data, name) { .data %&gt;% # o que faz isso? rename(id_lawsuit = n_processo) %&gt;% # o que faz isso? group_by(id_lawsuit) %&gt;% # o que faz isso? que raios são esses `!!` ?! nest(.key = !!name) %&gt;% # o que faz isso? ungroup() } Exercício: o que faz esse código? file_to_cpo &lt;- function(arq) { arq %&gt;% # o que faz isso? read_rds() %&gt;% # o que faz isso? imap(nest_infos) %&gt;% # o que faz isso? reduce(left_join, by = &quot;id_lawsuit&quot;) } Exercício: como você faria para montar a base de dados com esse código? Dica: você primeiro precisa listar os arquivos, aplicar funções a eles e por fim empilhar. O resultado deve ser uma tibble com 30000 linhas e 3 list columns # escreva código aqui "],
["calculando-tempos-e-intervalos-de-tempo.html", "5.5 Calculando tempos e intervalos de tempo", " 5.5 Calculando tempos e intervalos de tempo Um de nossos objetivos no projeto das especializações é estimar o tempo dos processos por fase. Para isso, precisamos filtrar as movimentações e obter intervalos de tempo que façam sentido. Nesse contexto, uma função de interesse poderia ter o código abaixo. summarise_dt &lt;- function(dt, txt, re, .fun, ignore_case = TRUE) { .fun(dt[str_detect(txt, regex(re, ignore_case = ignore_case))]) } A função summarise_dt() faz o seguinte: Recebe um vetor de datas dt e um vetor de movimentações txt de entrada, Filtra as datas cujos textos são compatíveis com uma regex, aplica uma função .fun para sumarizar essas datas. 5.5.1 estatísticas de movimentações Queremos aplicar summarise_dt() com diversos parâmetros diferentes, para a tabela de movimentações de cada processo. Vamos analisar a função abaixo. summarise_movs &lt;- function(m) { # partial assignment de summarise_dt partial_summarise_mov &lt;- partial(summarise_dt, dt = m$data_mov, txt = m$mov) # calcula várias estatísticas das movimentações summary_movs &lt;- tribble( ~tipo, ~name, ~re, ~.fun, # contagens &quot;n&quot;, &quot;julg&quot;, &quot;Trânsito|Julgado&quot;, length, &quot;n&quot;, &quot;baix&quot;, &quot;Baixa&quot;, length, &quot;n&quot;, &quot;recu&quot;, &quot;Recurso&quot;, length, &quot;n&quot;, &quot;sent&quot;, &quot;- Sentença&quot;, length, &quot;n&quot;, &quot;tudo&quot;, &quot;.*&quot;, length, # datas &quot;dt&quot;, &quot;julg&quot;, &quot;Trânsito|Julgado&quot;, min, &quot;dt&quot;, &quot;baix&quot;, &quot;Baixa&quot;, min, &quot;dt&quot;, &quot;recu&quot;, &quot;Recurso&quot;, min, &quot;dt&quot;, &quot;sent&quot;, &quot;- Sentença&quot;, min, &quot;dt&quot;, &quot;min&quot;, &quot;.*&quot;, min, &quot;dt&quot;, &quot;max&quot;, &quot;.*&quot;, max) %&gt;% mutate(val = map2(re, .fun, quietly(partial_summarise_mov)), val = map_dbl(val, &quot;result&quot;)) %&gt;% unite(variavel, tipo, name) %&gt;% select(variavel, val) %&gt;% # joga tudo para as colunas spread(variavel, val) %&gt;% # refaz colunas de datas mutate(tempo_total = dt_max - dt_min) %&gt;% mutate_at(vars(starts_with(&quot;dt_&quot;)), funs(as.Date(., origin = &quot;1970-01-01&quot;))) } Exercícios: O que faz a função tribble()? No código abaixo, quais funções são do dplyr, quais são do tidyr e quais são do purrr? O que faz mutate_at()? 5.5.2 Calculando intervalos de tempo O segredo para calcular intervalos de tempo é utilizar a função lag(). Esta é uma das funções do tipo janela, que são muito úteis para séries temporais e outras aplicações. summarise_decisions &lt;- function(d_movs) { # algumas regex re_decisao &lt;- regex(&quot;- Decisão| - Despacho&quot;, ignore_case = TRUE) re_concluso &lt;- regex(&quot;Concluso&quot;, ignore_case = TRUE) d_movs %&gt;% arrange(data_mov) %&gt;% # dados com lag mutate(last_mov = lag(mov), last_data_mov = lag(data_mov)) %&gt;% # somente movimentações em que há decisão filter(str_detect(mov, re_decisao)) %&gt;% # tempo entre movimentação atual e movimentação anterior mutate(tempo = data_mov - last_data_mov, tem_concluso = str_detect(mov, re_concluso)) %&gt;% # restrição: somamos apenas os casos em que não há concluso na mov # (pode ser que existam conclusos na movimentação com lag) summarise(n_deci_e_desp = length(mov), n_deci_n_nula = sum(!tem_concluso), t_deci = sum((!tem_concluso) * tempo, na.rm = TRUE)) } Finalmente, juntamos essas funções numa função que recebe uma tibble de movimentações e retorna uma tibble sumarizada. calcular_resumos &lt;- function(d_movs) { # limpeza das movimentações clean_movs &lt;- d_movs %&gt;% filter(!str_detect(&quot;Agravo&quot;, mov)) %&gt;% mutate(data_mov = dmy(data_mov)) %&gt;% group_by(data_mov) %&gt;% summarise(mov = str_c(mov, collapse = &quot;, &quot;)) # funções definidas acima summ_movs &lt;- summarise_movs(clean_movs) summ_decisions &lt;- summarise_decisions(clean_movs) # concatena os dois sumários bind_cols(summ_movs, summ_decisions) } 5.5.3 Resultados Quando a função é muito demorada, pode ser útil utilizar barras de progresso para acompanhar o andamento do download. É possível utilizar barras de progresso com o pacote progress, com uma pequena adaptação da função original. Exemplo: pb &lt;- progress::progress_bar$new(total = nrow(d_espec)) calcular_resumos_pb &lt;- function(x) { pb$tick() calcular_resumos(x) } Exercício: quais outras opções interessantes temos para barras de progresso? nãrd question: qual o tipo de objeto do progress? ## NAO RODE d_espec_resumida &lt;- d_espec %&gt;% # não vamos usar partes na análise select(id_lawsuit, d_infos, d_movs) %&gt;% # vamos abrir d_infos, já que tem só uma linha por processo unnest(d_infos) %&gt;% # vamos apenas analisar as varas cíveis do João Mendes filter(str_detect(vara, regex(&quot;vara cível&quot;, ignore_case = TRUE))) %&gt;% # adicionar as contagens! mutate(d_contas = map(d_movs, calcular_resumos_pb)) %&gt;% select(-d_movs) %&gt;% # explodir as contas unnest(d_contas) # leia aqui d_espec_resumida &lt;- read_rds(&quot;data-raw/espec/d_espec_resumida.rds&quot;) glimpse(d_espec_resumida) #&gt; Observations: 27,892 #&gt; Variables: 22 #&gt; $ id_lawsuit &lt;chr&gt; &quot;0004007-47.2013.8.26.0368&quot;, &quot;0001909-75.2013.8.... #&gt; $ comarca &lt;chr&gt; &quot;Foro Central Cível&quot;, &quot;Foro Central Cível&quot;, &quot;For... #&gt; $ foro &lt;chr&gt; &quot;Foro Central Cível&quot;, &quot;Foro Central Cível&quot;, &quot;For... #&gt; $ vara &lt;chr&gt; &quot;39ª Vara Cível&quot;, &quot;34ª Vara Cível&quot;, &quot;14ª Vara Cí... #&gt; $ classe &lt;chr&gt; &quot;Procedimento Comum&quot;, &quot;Exibição&quot;, &quot;Procedimento ... #&gt; $ assunto &lt;chr&gt; &quot;Obrigação de Fazer / Não Fazer&quot;, &quot;Medida Cautel... #&gt; $ data_dist &lt;chr&gt; &quot;23/08/2013&quot;, &quot;17/01/2013&quot;, &quot;10/05/2013&quot;, &quot;14/05... #&gt; $ dt_baix &lt;date&gt; NA, NA, NA, 2015-01-07, NA, 2014-02-13, 2014-03... #&gt; $ dt_julg &lt;date&gt; NA, NA, NA, 2015-01-07, NA, 2013-11-12, 2014-01... #&gt; $ dt_max &lt;date&gt; 2015-05-13, 2016-03-18, 2016-06-13, 2015-01-07,... #&gt; $ dt_min &lt;date&gt; 2013-08-23, 2013-01-17, 2013-05-10, 2013-05-14,... #&gt; $ dt_recu &lt;date&gt; 2014-10-01, NA, NA, NA, NA, NA, NA, NA, NA, NA,... #&gt; $ dt_sent &lt;date&gt; 2014-07-14, 2015-05-21, 2014-01-27, 2014-11-19,... #&gt; $ n_baix &lt;dbl&gt; 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, ... #&gt; $ n_julg &lt;dbl&gt; 0, 0, 0, 1, 0, 2, 2, 0, 3, 0, 0, 0, 0, 0, 0, 0, ... #&gt; $ n_recu &lt;dbl&gt; 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ... #&gt; $ n_sent &lt;dbl&gt; 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, ... #&gt; $ n_tudo &lt;dbl&gt; 41, 35, 38, 50, 65, 27, 25, 3, 64, 33, 15, 30, 4... #&gt; $ tempo_total &lt;dbl&gt; 628, 1156, 1130, 603, 795, 254, 267, 218, 962, 1... #&gt; $ n_deci_e_desp &lt;int&gt; 6, 3, 4, 4, 6, 5, 2, 0, 3, 4, 2, 2, 5, 5, 4, 9, ... #&gt; $ n_deci_n_nula &lt;int&gt; 6, 3, 1, 3, 5, 1, 0, 0, 2, 4, 1, 2, 4, 5, 2, 7, ... #&gt; $ t_deci &lt;time&gt; 239 days, 184 days, 8 days, 22 days, 5 days, 13... library(survival) d_surv &lt;- d_espec_resumida %&gt;% mutate(t_deci = as.numeric(t_deci)) %&gt;% gather(tipo_tempo, tempo, tempo_total, t_deci) %&gt;% mutate(obs = n_baix &gt; 0 | n_julg &gt; 0 | n_sent &gt; 0) %&gt;% filter(tempo &gt;= 0, tempo &lt; 1400) fit &lt;- survfit(Surv(tempo, obs) ~ tipo_tempo, data = d_surv) survminer::ggsurvplot(fit, risk.table = TRUE) 5.5.4 Wrap-up de hoje Terminamos o projeto das câmaras Aprendemos tidyr no meio do caminho revisitamos ggplot2 e brincamos de visualização. Aprendemos as funções do purrr. Principais: map(), map_*(). Montamos a base de dados do projeto de especialização. Usando todos os pacotes juntos. Próxima aula: Modelos! - Sobrevivência - Captcha - Rede bayesiana (se der tempo) "],
["modelos.html", "Capítulo 6 Modelos", " Capítulo 6 Modelos Passamos boa parte da graduação nessa parte. Na jurimetria, demora bastante para chegar na fase de rodar modelos. Muitas vezes, no final da pesquisa um gráfico de barras é suficiente para responder às perguntas da pesquisa. Em uma fração pequena dos dados, que vem aumentando com o tempo, é necessário ajustar modelos mais sofisticados. Na última vez, vimos tidyr, o alicate das bases de dados Finalizamos o projeto das câmaras Estudamos o maravilhoso mundo de purrr Nessa última aula vamos ver Exemplo de aplicação de análise de sobrevivência. Quebrando Captchas com o R. 6.0.1 Setup Logar no servidor http://r.abj.org.br No projeto r4jurimetrics, aba git -&gt; Pull Abrir o arquivo 03-vectors.Rmd Rodar library(tidyverse) "],
["sobrevivencia.html", "6.1 Sobrevivência", " 6.1 Sobrevivência Análise de sobrevivência serve para ajustar modelos com informações censuradas. A grande diferença desse tipo de modelo está na contribuição que uma observação tem na verossimilhança do modelo. Quando temos informação pontual, a contribuição da observação \\(i\\) na verossimilhança é dada por \\[ f(t_i|\\theta) \\] Quando temos informação censurada, só sabemos que \\(x_i &gt; t_i\\), logo a contribuição é dada por \\[ P(X_i &gt; t_i|\\theta) = 1-F(t_i|\\theta) = S(t_i|\\theta) \\] Assim, a verossimilhança é dada por \\[ L(x|\\theta) = \\prod_{i=1}^n f(t_i|\\theta)^{\\delta_i} S(t_i|\\theta)^{(1-\\delta_i)} \\] em que \\(\\delta_i\\) é um indicador de observação pontual (não-censurada). O modelo mais conhecido de análise de sobrevivência é o Kaplan-Meier, um modelo que estima a curva de sobrevivência através da seguinte conta \\[ \\hat{S}(t) = \\prod_{i:t_i\\leq t}\\left(1-\\frac{d_i}{n_i}\\right) \\] onde \\(d_i\\) é o número de eventos ocorridos até o momento e \\(n_i\\) é o número de processos vivos no tempo do indivíduo \\(i\\). Essa conta leva a censura em conta de forma adequada e existem diversas razões teóricas para sua utilização. 6.1.1 Base de dados A base de dados final desse projeto, após a realização de todos os filtros e sumarizações, além da análise da cifra oculta, está armazenada no objeto d_fcc (dados Fórum Central Cível). library(tidyverse) d_fcc &lt;- readRDS(&quot;data/d_fcc.rds&quot;) %&gt;% mutate(censura = as.numeric(pmax(julgado, baixa, recurso, sentenca)), censura = if_else(censura &gt; 0, 1, 0)) %&gt;% mutate(t_deci_total = n_deci_e_desp * t_deci) %&gt;% filter(tipo != &quot;RJ&quot;, tempo_total &gt; 0, tempo_total &lt; 1700) glimpse(d_fcc) #&gt; Observations: 329,578 #&gt; Variables: 28 #&gt; $ n_processo &lt;chr&gt; &quot;0000014-24.2013.8.26.0003&quot;, &quot;0000017-82.2013.8.... #&gt; $ comarca &lt;chr&gt; &quot;Foro Central Cível&quot;, &quot;Foro Central Cível&quot;, &quot;For... #&gt; $ foro &lt;chr&gt; &quot;Foro Central Cível&quot;, &quot;Foro Central Cível&quot;, &quot;For... #&gt; $ vara &lt;chr&gt; &quot;26ª Vara Cível&quot;, &quot;19ª Vara Cível&quot;, &quot;2ª Vara Cív... #&gt; $ classe &lt;chr&gt; &quot;Alienação Judicial de Bens&quot;, &quot;Procedimento Comu... #&gt; $ assunto &lt;chr&gt; &quot;Alienação Judicial&quot;, &quot;Indenização por Dano Mora... #&gt; $ data_dist &lt;date&gt; 2013-01-07, 2013-01-30, 2013-01-07, 2013-01-07,... #&gt; $ n_deci &lt;int&gt; 3, 3, 0, 1, 5, 5, 4, 5, 2, 6, 6, 6, 2, 2, 0, 1, ... #&gt; $ n_desp &lt;int&gt; 2, 0, 4, 5, 7, 0, 3, 3, 4, 2, 1, 2, 0, 4, 1, 2, ... #&gt; $ n_mov &lt;int&gt; 36, 24, 26, 36, 54, 48, 59, 73, 55, 82, 25, 43, ... #&gt; $ tempo_total &lt;dbl&gt; 319, 439, 823, 1303, 1323, 1244, 634, 1311, 1304... #&gt; $ julgado &lt;int&gt; 0, 0, 1, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, ... #&gt; $ baixa &lt;int&gt; 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, ... #&gt; $ recurso &lt;int&gt; 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ... #&gt; $ sentenca &lt;int&gt; 2, 1, 1, 2, 2, 1, 1, 0, 1, 2, 0, 2, 0, 1, 3, 2, ... #&gt; $ prim_mov &lt;date&gt; 2013-01-07, 2013-01-30, 2013-01-07, 2013-01-07,... #&gt; $ ult_mov &lt;date&gt; 2013-11-22, 2014-04-14, 2015-04-10, 2016-08-02,... #&gt; $ data_julgado &lt;date&gt; NA, NA, 2015-04-10, NA, NA, 2013-12-12, NA, NA,... #&gt; $ data_baixa &lt;date&gt; 2013-11-21, 2014-04-14, 2015-04-10, NA, NA, NA,... #&gt; $ data_recurso &lt;date&gt; NA, NA, NA, NA, 2016-05-10, NA, NA, NA, NA, NA,... #&gt; $ data_sentenca &lt;date&gt; 2013-09-26, 2014-01-17, 2013-10-14, 2013-06-21,... #&gt; $ n_deci_e_desp &lt;int&gt; 5, 3, 4, 6, 11, 5, 7, 7, 6, 8, 7, 8, 2, 6, 1, 3,... #&gt; $ t_deci &lt;dbl&gt; 10.200000, 23.333333, 80.250000, 8.000000, 25.54... #&gt; $ n_deci_n_nula &lt;dbl&gt; 4, 3, 4, 6, 11, 5, 7, 7, 3, 4, 7, 6, 1, 5, 1, 2,... #&gt; $ p &lt;dbl&gt; 0.00000000, 0.00000000, 0.00000000, 0.00000000, ... #&gt; $ tipo &lt;chr&gt; &quot;Comum&quot;, &quot;Comum&quot;, &quot;Comum&quot;, &quot;Comum&quot;, &quot;Comum&quot;, &quot;Em... #&gt; $ censura &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, ... #&gt; $ t_deci_total &lt;dbl&gt; 51, 70, 321, 48, 281, 187, 105, 166, 16, 6, 332,... 6.1.2 Ajustando de modelos no R O pacote utilizado para ajuste de modelos Surv() serve para criar a variável resposta do modelo considerando as duas variáveis que a compõem: tempo e indicador de não-censura survfit() ajusta o kaplan-meier (ou outros modelos) para uma fórmula com Surv() do lado esquerdo do ~ e outras covariáveis do lado direito. library(survival) Modelando o tempo total do processo. A função broom::tidy() mostra os principais achados do modelo numa base de dados arrumada, para ser posteriormente utilizada. modelo_tempo_total &lt;- d_fcc %&gt;% with(survfit(Surv(tempo_total, censura) ~ tipo)) modelo_tempo_total %&gt;% broom::tidy() Modelando o tempo de decisão modelo_tempo_decisao &lt;- d_fcc %&gt;% with(survfit(Surv(t_deci_total, censura) ~ tipo)) modelo_tempo_decisao %&gt;% broom::tidy() O pacote broom existe para diversos modelos e ajuda bastante a trabalhar com os resultados de ajustes. Dê uma olhada em https://github.com/tidyverse/broom para detalhes. 6.1.3 Curvas de sobrevivência Atualmente, o melhor pacote para fazer curvas de sobrevivência é o survminer. Basta rodar a função ggsurvplot: survminer::ggsurvplot(modelo_tempo_total, risk.table = TRUE, data = d_fcc) survminer::ggsurvplot(modelo_tempo_decisao, risk.table = TRUE, data = d_fcc) Dá para observar que processos empresariais são mais lentos, mas não dá pra ver quase nada nesses gráficos. Por isso comparamos as curvas utilizando uma estatística das ruas. 6.1.4 Comparação das curvas plota_grafico_dificuldade &lt;- function(broom_model) { # empresarial d_e &lt;- broom_model %&gt;% filter(strata == &quot;tipo=Empresarial&quot;) # comum d_c &lt;- broom_model %&gt;% filter(strata == &quot;tipo=Comum&quot;) # fuzzyjoin das duas curvas fuzzyjoin::difference_inner_join(d_e, d_c, &#39;estimate&#39;, max_dist = 0.01) %&gt;% mutate(razao = time.x/time.y, dificuldade = as.factor(cut(1-estimate.x, breaks = 10, labels = FALSE, include.lowest = TRUE))) %&gt;% group_by(dificuldade) %&gt;% summarise(razao = mean(razao)) %&gt;% ggplot(aes(x = as.numeric(dificuldade), y = razao)) + geom_col(fill = &#39;royalblue&#39;) + theme_minimal(17) } Tempo total: modelo_tempo_total %&gt;% broom::tidy() %&gt;% plota_grafico_dificuldade() + geom_hline(yintercept = 1, linetype = 1) + scale_y_continuous(limits = c(0, 1.5), labels = scales::percent) + labs(x = &quot;Dificuldade do caso&quot;, y = &quot;Razão entre os tempos medianos&quot;) + ggtitle(&quot;Razão dos tempo total versus dificuldade&quot;) Tempo da decisão: modelo_tempo_decisao %&gt;% broom::tidy() %&gt;% plota_grafico_dificuldade() + geom_hline(yintercept = 1, linetype = 1) + geom_hline(yintercept = 2, linetype = 2) + labs(x = &quot;Dificuldade do caso&quot;, y = &quot;Razão entre os tempos medianos&quot;) + ggtitle(&quot;Razão dos tempo de decisão versus dificuldade&quot;) + scale_y_continuous(labels = scales::percent) 6.1.5 Resultados Como resultados dessa análise, concluímos que Processos empresariais de fato são mais complexos que processos cíveis. A diferença é menor em processos de alta complexidade. A diferença também é maior quando consideramos somente o tempo de decisões e não o tempo total. "],
["captchas-sim-captchas.html", "6.2 CAPTCHAs? SIM, CAPTCHAs", " 6.2 CAPTCHAs? SIM, CAPTCHAs Sabe aquelas imagens chatas que aparecem quando você está preenchendo um formulário ou quer acessar uma página específica, pedindo para você decifrar o texto? Isso é o que chamamos de CAPTCHA (Completely Automated Public Turing test to tell Computers and Humans Apart). Captchas foram criados para impedir que robôs acessem determinadas páginas na web de forma irrestrita. Algumas empresas como a Google também usam essas coisinhas para utilizar o conhecimento de seres humanos para dominar o mundo. library(decryptr) &#39;imgs/receita/captcha48ec12131bab.png&#39; %&gt;% read_captcha() %&gt;% plot() Figura 6.1: Exemplo de CAPTCHA: Consulta de CNPJ da Receita Federal. Existem captchas de todo tipo: difíceis, fáceis, que fazem sentido e que não fazem sentido. Um exemplo de CAPTCHA que faz sentido são os presentes em formulários para criação de emails. Imagine se alguém fizesse um programa que criasse bilhões de contas de e-mail do gmail! Um exemplo de CAPTCHA que não faz sentido são os sites de serviços públicos, como a Receita Federal ou de alguns Tribunais de Justiça. Algumas justificativas para isso são: i) não onerar os sistemas ou ii) a falsa ideia de que assim estão protegendo as pessoas. Pensando nisso, fiquei imaginando: Será que é possível quebrar CAPTCHAs usando modelos estatísticos? Tornando curta uma história longa, sim, é possível! O resultado dessa brincadeira está na organização decryptr. Claro que não são todos os CAPTCHAs que conseguimos quebrar, mas estamos fazendo pesquisa, brincando nas Rackathons (hackathons com R) e discutindo várias ideias para tornar isso viável. É um esforço da comunidade para tornar os serviços públicos mais acessíveis. "],
["pacote-decryptr.html", "6.3 Pacote decryptr", " 6.3 Pacote decryptr No meu último post anunciei que começaríamos uma série sobre CAPTCHAs. Uma da nossas iniciativas principais nesse tema é a criação do pacote decryptr. Hoje veremos como usar algumas das funções principais desse pacote. 6.3.1 Suposições do decryptr Ao criar o decryptr reduzimos um pouco o escopo de CAPTCHAs que gostaríamos de incluir. Fizemos isso para não ficarmos malucos, pois existem diversos tipos de testes disponíveis na web! As suposições são: Apenas imagens jpg ou png. Uma imagem possui apenas números e letras. A quantidade de caracteres de um CAPTCHA é fixa. Dois CAPTCHAs de mesma origem têm sempre as mesmas dimensões. Não conseguimos nem queremos quebrar o reCAPTCHA. 6.3.2 Instalação O decryptr ainda não está no CRAN. Isso significa que para instalá-lo você precisará do devtools: devtools::install_github(&#39;decryptr/decryptr&#39;) As funções principais do decryptr são download_captcha(): baixar imagens da web. read_captcha(): adiciona metadados úteis a uma string com o caminho do CAPTCHA. load_captcha(): carrega a imagem na memória. plot.captcha(): método S3 para desenhar o CAPTCHA na tela. classify(): método S3 para classificar CAPTCHAs manualmente. load_model(): carrega um modelo já ajustado e guardado no pacote decryptrModels train_model(): método S3 para ajustar um modelo para os CAPTCHAs. decrypt(): método S3 para classificar um CAPTCHA a partir de um modelo ajustado e um caminho de imagem. 6.3.3 Fluxo de utilização O modo de uso planejado do decryptr está descrito na Figura 6.2. Figura 6.2: Fluxo de utilização do pacote decryptr. 6.3.4 Download A função download_captcha() tem cinco parâmetros: url= o link do CAPTCHA que queremos baixar. n= a quantidade de CAPTCHAs a serem baixados. path= a pasta que queremos salvar a imagem. secure= se TRUE, fará o download com a opção ssl_verifypeer = FALSE (veja esse post) ext= extensão do arquivo (jpg/jpeg ou png). Essa não é uma das funções mais seguras do mundo, já que dependemos de uma boa conexão com o servidor de onde os CAPTCHAs serão baixados. A função também não trata de problemas com bloqueio de IP. Para facilitar a utilização do decryptr, adicionamos algumas atalhos do tipo download_captcha(&quot;nome&quot;), que já contêm os padrões para download de alguns sites específicos: download_captcha(&quot;rfb&quot;): Consulta de CNPJ da Receita federal. download_captcha(&quot;saj&quot;): Sistema SAJ (vários Tribunais Estaduais). download_captcha(&quot;tjmg&quot;): Tribunal de Justiça de Minas Gerais. download_captcha(&quot;tjrj&quot;): Tribunal de Justiça do Rio de Janeiro. download_captcha(&quot;tjrs&quot;): Tribunal de Justiça do Rio Grande do Sul. download_captcha(&quot;trt&quot;): Tribunais Regionais do Trabalho. Exemplo: library(decryptr) # salva arquivo em ./img/tjmg/captcha&lt;id&gt;.jpeg arq &lt;- download_captcha(&quot;tjmg&quot;, n = 1, path = &#39;imgs/tjmg&#39;) arq 6.3.5 Visualização Para plotar um CAPTCHA basta ler o arquivo com read_captcha() e depois usar a função plot(). Exemplo: library(decryptr) &#39;imgs/tjmg/captcha4bfc85b5532.jpeg&#39; %&gt;% read_captcha() %&gt;% plot() Figura 6.3: CAPTCHA do TJMG. Vale mencionar que esse não é um ggplot(), então nem tente somar layers! 6.3.6 Classificação A classificação manual de CAPTCHAs é importante para possibilitar o treino de modelos preditivos. Para classificar um CAPTCHA você pode utilizar a função classify(), assim: &#39;imgs/tjmg/captcha4bfc85b5532.jpeg&#39; %&gt;% classify() Figura 6.4: Classificando CAPTCHA do TJMG. #&gt; Answer: #&gt; [1] &quot;imgs/tjmg/captcha4bfc85b5532_.jpeg&quot; Essa função fará duas coisas: Plota o CAPTCHA na tela. Abre um console para o usuário digitar o valor do CAPTCHA manualmente. Ao escrever o valor o CAPTCHA, pressione &lt;enter&gt;. Após isso, a função classify() irá adicionar sua classificação após o nome da imagem, como no exemplo acima: _92522. A função classify() gera uma cópia para que seja impossível de perder a imagem original. Algumas opções do classify(): answers= adicionar uma resposta ao invés de esperar abrir o console. Essa opção é útil quando as classficações são feitas automaticamente (e.g., por um quebrador de CAPTCHAs que usa o áudio no lugar da imagem.) path= colocar uma pasta para classificar os CAPTCHAs. Por padrão é a pasta onde os originais estão. 6.3.7 Carregar modelo A função load_model() é responsável por carregar modelos pré treinados modelo &lt;- decryptr::load_model(&quot;tjmg&quot;) modelo$model #&gt; Model #&gt; ___________________________________________________________________________ #&gt; Layer (type) Output Shape Param # #&gt; =========================================================================== #&gt; conv2d_4 (Conv2D) (None, 40, 110, 4) 104 #&gt; ___________________________________________________________________________ #&gt; max_pooling2d_4 (MaxPooling2D) (None, 20, 55, 4) 0 #&gt; ___________________________________________________________________________ #&gt; conv2d_5 (Conv2D) (None, 20, 55, 16) 1616 #&gt; ___________________________________________________________________________ #&gt; max_pooling2d_5 (MaxPooling2D) (None, 10, 27, 16) 0 #&gt; ___________________________________________________________________________ #&gt; conv2d_6 (Conv2D) (None, 10, 27, 32) 12832 #&gt; ___________________________________________________________________________ #&gt; max_pooling2d_6 (MaxPooling2D) (None, 5, 13, 32) 0 #&gt; ___________________________________________________________________________ #&gt; flatten_2 (Flatten) (None, 2080) 0 #&gt; ___________________________________________________________________________ #&gt; dense_3 (Dense) (None, 16) 33296 #&gt; ___________________________________________________________________________ #&gt; dropout_2 (Dropout) (None, 16) 0 #&gt; ___________________________________________________________________________ #&gt; dense_4 (Dense) (None, 50) 850 #&gt; ___________________________________________________________________________ #&gt; reshape_2 (Reshape) (None, 5, 10) 0 #&gt; ___________________________________________________________________________ #&gt; activation_2 (Activation) (None, 5, 10) 0 #&gt; =========================================================================== #&gt; Total params: 48,698 #&gt; Trainable params: 48,698 #&gt; Non-trainable params: 0 #&gt; ___________________________________________________________________________ 6.3.8 Quebrar captcha A função decrypt quebra o captcha a partir de uma imagem e um modelo. decrypt(&#39;imgs/tjmg/captcha4bfc85b5532.jpeg&#39;, modelo) #&gt; [1] &quot;24485&quot; Você também pode chamar decrypt com o nome do modelo no lugar do próprio modelo carregado, mas isso é ineficiente Exercícios Baixe 1 captcha para cada origem disponível no decryptr. Algum deles não funciona? Desenhe esses captchas. Algum deles não funciona? Quebre esse captcha usando decrypt. Algum deles não funciona? "],
["segmentacao.html", "6.4 Segmentação", " 6.4 Segmentação Nesse post vamos discutir um pouco sobre modelar CAPTCHAs. Vou assumir que você já viu o post de introdução e o post sobre download, leitura e classificação manual de CAPTCHAs. Digamos que você tenha uma base de dados de treino composta por \\(N\\) imagens com os textos classificados. Nossa resposta nesse caso é uma palavra de \\(k\\) caracteres (vamos considerar \\(k\\) fixado), sendo que cada caractere \\(c\\) pode ter \\(p\\) valores. O problema de modelar o CAPTCHA diretamente é que a variável resposta tem um número exponencial de combinações de acordo com o número de caracteres: \\[ \\Omega = p^k. \\] Por exemplo, um CAPTCHA com \\(k=6\\) e \\(p=36\\) (26 letras e 10 números), que é muito comum, possui um total de 2.176.782.336 (&gt; 2 bilhões) combinações! E não preciso dizer que é completamente inviável baixar e modelar tudo isso de CAPTCHAs. A alternativa imediata que aparece é tentar separar a imagem em um pedaço para cada caractere e fazer um modelo para prever caracteres. Assim nossa resposta é reduzida para \\(p\\) categorias, que é bem mais fácil de tratar. Vamos usar como exemplo o CAPTCHA do TJMG. Primeiro, o download: arq_captcha &lt;- decryptr::download_captcha(&quot;tjmg&quot;, n = 1, path = &#39;imgs/captcha&#39;) Visualizando a imagem: library(decryptr) arq_captcha &lt;- &quot;imgs/captcha/captcha4c9f411d0391.jpeg&quot; arq_captcha %&gt;% read_captcha() %&gt;% plot() Figura 6.5: CAPTCHA do TJMG. Exercício: Sem separar as letras, quantas combinações temos no TJMG? Infelizmente, segmentar a imagem nos lugares corretos é uma tarefa difícil. Pior até do que predizer as letras. Para simplificar, vamos fazer um corte fixado das letras: arq_captcha %&gt;% read_captcha() %&gt;% plot() abline(v = 26 + 20 * 0:3, col = &#39;red&#39;) Figura 6.6: Linhas verticais separando letras Podemos também limitar os eixos x (tirar os espaços vazios à esquerda e à direita) e y (superiores e inferiores). op &lt;- graphics::par(mar = rep(0, 4)) arq_captcha %&gt;% read_captcha() %&gt;% dplyr::first() %&gt;% with(x) %&gt;% magrittr::extract(-c(1:7, 34:dim(.)[1]), -c(1:06, 107:dim(.)[2]), TRUE) %&gt;% grDevices::as.raster() %&gt;% graphics::plot() abline(v = 20 * 1:4, col = &#39;red&#39;) abline(h = c(0, 26), col = &#39;blue&#39;) Agora temos uma imagem de tamanho dimensões 26x20 por caractere. Nosso próximo desafio é transformar isso em algo tratável por modelos de regressão. Para isso, colocamos cada pixel em uma coluna da nossa base de dados. No caso do TRT, cada CAPTCHA gerará uma tabela de 6 linhas e 520 (26 * 20) colunas. Podemos usar esse código para montar: arq_captcha %&gt;% read_captcha() %&gt;% dplyr::first() %&gt;% with(x) %&gt;% magrittr::extract(-c(1:7, 34:dim(.)[1]), -c(1:06, 107:dim(.)[2]), TRUE) %&gt;% as_tibble() %&gt;% rownames_to_column(&#39;y&#39;) %&gt;% gather(x, value, -y) %&gt;% mutate_at(vars(x, y), funs(parse_number)) %&gt;% mutate(letra = (x - 1) %/% 20 + 1, x = x - (letra - 1) * 20) %&gt;% mutate_at(vars(x, y), funs(sprintf(&#39;%02d&#39;, .))) %&gt;% unite(xy, x, y) %&gt;% spread(xy, value, sep = &#39;&#39;) %&gt;% mutate(y = c(&#39;1&#39;, &#39;0&#39;, &#39;0&#39;, &#39;1&#39;, &#39;7&#39;)) %&gt;% select(y, everything(), -letra) p &lt;- progress::progress_bar$new(total = 1500) dados_segment &lt;- &#39;data-raw/captcha&#39; %&gt;% dir(full.names = TRUE, pattern = &#39;_&#39;) %&gt;% map_dfr(~{ p$tick() # pega a resposta dos arquivos words &lt;- .x %&gt;% basename() %&gt;% tools::file_path_sans_ext() %&gt;% stringr::str_match(&quot;_([0-9]+)$&quot;) %&gt;% magrittr::extract(TRUE, 2) %&gt;% stringr::str_split(&#39;&#39;, simplify = TRUE) %&gt;% as.character() # carrega o bd do arquivo (codigo anterior) .x %&gt;% read_captcha() %&gt;% dplyr::first() %&gt;% with(x) %&gt;% magrittr::extract(-c(1:7, 34:dim(.)[1]), -c(1:06, 107:dim(.)[2]), TRUE) %&gt;% as_tibble() %&gt;% rownames_to_column(&#39;y&#39;) %&gt;% gather(x, value, -y) %&gt;% mutate_at(vars(x, y), funs(parse_number)) %&gt;% mutate(letra = (x - 1) %/% 20 + 1, x = x - (letra - 1) * 20) %&gt;% mutate_at(vars(x, y), funs(sprintf(&#39;%02d&#39;, .))) %&gt;% unite(xy, x, y) %&gt;% spread(xy, value, sep = &#39;&#39;) %&gt;% mutate(y = words) %&gt;% select(y, everything(), -letra) }, .id = &#39;captcha_id&#39;) saveRDS(dados_segment, &#39;data/dados_segment.rds&#39;, compress = &#39;bzip2&#39;) Muito bem! Agora basta rodar o mesmo para toda a base de treino e rodar um modelo. Vamos usar uma base de 1500 CAPTCHAs classificados. Essa base fica com 7500 linhas e 520 colunas. Vamos usar 6000 linhas para treino e as 1500 restantes para teste. O modelo utilizado será um randomForest padrão. library(randomForest) dados &lt;- readRDS(&#39;data/dados_segment.rds&#39;) %&gt;% mutate(y = factor(y)) # monta bases de treino e teste set.seed(4747) # reprodutibilidade ids_treino &lt;- sample(seq_len(nrow(dados)), 6000, replace = FALSE) d_train &lt;- dados[ids_treino, ] d_test &lt;- dados[-ids_treino, ] model_rf &lt;- randomForest(y ~ . - captcha_id, data = d_train) # saveRDS(model_rf, &#39;data/model_segment_rf.rds&#39;, compress = &#39;bzip2&#39;) model_rf &lt;- readRDS(&#39;data/model_segment_rf.rds&#39;) O resultado do modelo pode ser verificado na tabela de observados versus preditos na base de teste. O acerto foi de 99.5% em cada caractere! Assumindo que o erro não depende da posição do caractere no CAPTCHA, teremos um acerto de aproximadamente 97.5% para a imagem. d_test %&gt;% mutate(pred = predict(model_rf, newdata = .)) %&gt;% count(y, pred) %&gt;% spread(pred, n, fill = &#39;.&#39;) %&gt;% remove_rownames() %&gt;% knitr::kable(caption = &#39;Tabela de acertos e erros.&#39;) y 0 1 2 3 4 5 6 7 8 9 0 156 . . . . . . . . . 1 . 160 . . . . . . . . 2 . . 147 . . . . . . . 3 . . 1 140 . . . . . . 4 . 2 . . 150 . . . . . 5 . . . . . 153 . . . . 6 . . . . . . 143 . . . 7 . . . . . . . 152 . . 8 . . . 2 1 . . . 139 . 9 . . . . . . . . . 154 6.4.1 Nem tudo são rosas O resultado para o CAPTCHA do TJMG é bastante satisfatório, mas infelizmente não generaliza para outros CAPTCHAs. Tome por exemplo o CAPTCHA da Receita Federal abaixo. Nesse caso, a posição dos caracteres muda significativamente de imagem para imagem, e assim fica difícil cortar em pedaços. dir(&#39;imgs/receita&#39;, full.names = TRUE) %&gt;% purrr::walk(~plot(magick::image_read(.x))) O mesmo modelo aplicado ao CAPTCHA da Receita possui acerto de 78.8% do caractere, o que equivale a apenas 23.8% de acerto para toda a imagem. Veja os resultados na tabela abaixo. 6.4.2 Exercício Por quê você acha que o modelo da receita é pior? O que você faria para melhorar o poder preditivo? Claro que seria possível melhorar o poder preditivo com uma modelagem mais cuidadosa: nós usamos todos os parâmetros padrão da randomForest e não consideramos outros possíveis modelos. Mas acreditamos que o problema essencial está na segmentação, e não na modelagem após a segmentação. Nos próximos posts, vamos mostrar como resolver o CAPTCHA da Receita com maior acurácia utilizando técnicas de Deep Learning que consideram a etapa de segmentação dentro da modelagem. 6.4.3 Wrap-up Não dá para considerar todas as combinações de valores de um CAPTCHA diretamente num modelo de regressão. Uma forma de resolver um CAPTCHA é segmentando a imagem em pedaços de mesma largura. Para montar a base de treino, criamos uma coluna para cada pixel. Um CAPTCHA corresponde a uma base com \\(k\\) linhas e número de colunas igual ao número de pixels. No CAPTCHA do TJMG os resultados são satisfatórios. Já para CAPTCHA da Receita essa estratégia pode ser ineficaz. Vamos evoluir essa análise para técnicas que consideram a etapa de segmentação dentro da modelagem. "],
["estrutura-de-dados.html", "6.5 Estrutura de Dados", " 6.5 Estrutura de Dados No último post sobre CAPTCHAs nós vimos que a segmentação das imagens (separar uma imagem em várias imagens, uma para cada caractere) é um problema complicado. Definir uma largura fixa ou utilizar outros métodos ad-hoc para segmentar as imagens pode dar bons frutos, mas não é o suficiente para quebrar CAPTCHAs mais complexos, como o da Receita Federal. Alguns meses atrás, tentamos resolver esse problema de várias formas. Uma delas foi utilizar algoritmos de agrupamento (\\(k\\)-médias) ou de identificação de conjuntos conectados. Esses algoritmos se mostraram instáveis e não aumentaram muito o poder preditivo. Outra ideia que tentamos foi criar vários critérios de corte fixos e incluir todas as colunas geradas na base de dados. Mas isso deixou nos deixou com uma dimensão muito grande pra tratar, e parecia que os modelos precisavam de muito mais dados pra começarem a funcionar. Foi aí que o Daniel nos disse que estava trabalhando no pacote do Keras e que existia uma forma de trabalhar com a imagem completa, sem segmentar. A tarefa de segmentação seria “parametrizada” num modelão complexo de deep learning e conseguiríamos resolver o problema sem pré-processamento. Inicialmente, eu e o Athos ficamos perplexos com a ideia. Foi só quando o Daniel mostrou um modelo que acertava 100% dos CAPTCHAs do TJMG que fomos convencidos, e passamos a chamar esse modelo de “magia negra”. Vamos discutir como montar a base para fazer a magia negra. 6.5.1 Resposta Nossa resposta não é mais uma categoria, e sim uma matriz. A matriz tem \\(k\\) linhas (número de letras em um CAPTCHA) \\(p\\) colunas (número de valores possíveis de um caractere). O elemento \\((i,j)\\) vale 1 se na posição \\(i\\) aparece a letra relativa à posição \\(j\\). Assim, g3kvjg vira isso: (substituí 0 por '.' para ficar mais fácil de ver) m &lt;- &quot;imgs/receita/captcha48ec12131bab_g3kvjg.png&quot; %&gt;% read_captcha(ans_in_path = TRUE) %&gt;% first() %&gt;% with(y) m[m == 0] &lt;- &#39;.&#39; as_tibble(m) %&gt;% rownames_to_column(&#39;posicao&#39;) Isso para uma imagem. Vamos precisar de uma terceira dimensão, que são as “linhas” de nossa resposta (uma para cada CAPTCHA). Nosso y final é um array de dimensões \\(n \\times k \\times p\\). Achou estranho? Estamos só começando! 6.5.2 Explicativas Uma imagem nada mais é do que uma matriz de pixels. Cada elemento da matriz é um número entre zero e um indicando o quanto de cor há nesse pixel. Assim, zero significa preto (ausência de cor), e um significa branco (todas as cores). Valores intermediários dão escala de cinza. Para representar imagens com cores, é necessária uma terceira dimensão de tamanho 3, indicando os pesos de R (red) G (green) e B (blue), mas não faremos isso. Assim, nossa base de dados de explicativas é um array de dimensões \\[ n \\times h \\times w \\times 1 \\] em que \\(h\\) e \\(w\\) são a altura e a largura da imagem, respectivamente. "],
["redes-neurais-com-keras.html", "6.6 Redes neurais com keras", " 6.6 Redes neurais com keras Agora vamos estudar um pouco de redes neurais! 6.6.1 Novos tempos? Nos últimos anos os tipos de dados mudaram. Hoje qualquer coisa é considerada dado, e tudo está vindo em um volume gigante. Coisas muito importantes hoje em dia: Em paralelo (ou como consequência), tivemos diversos avanços na estatística: Regularização Inferência Bayesiana Modelos não paramétricos Outros Tudo isso está inserido numa caixinha chamada statistical learning. Muito disso se deve aos avanços computacionais, como Coisas na cloud; computação barata Paralelização O advento das GPU Mas não foi só isso. O que temos hoje também é fruto de uma comunidade cada vez mais ativa, interdisciplinar e colaborativa Popularização do Github Popularização do R e do python Análises reprodutíveis 6.6.2 Deep Learning Mas afinal, o que é o deep learning? Popularidade recente da área de deep learning. Promete fazer muitas coisas. Tem um linguajar diferente do que estamos acostumados. Essa é a imagem mais encontrada quando pesquisamos esse conceito 6.6.3 Problemas Muita, muita gente usando. Mercado está pedindo. Só se fala nisso. Falsa ideia de que não aprendemos nada sobre isso na faculdade O que estudamos é ultrapassado? Juntando com o marketing, temos a era da depressão dos estatísticos 6.6.4 Não entre em pânico! Existem muitos falsos cognatos. A maioria das coisas que estudamos é útil. E, ainda assim, vale à pena estudar os conceitos. "],
["regressao-logistica.html", "6.7 Regressão logística", " 6.7 Regressão logística Componente aleatório \\[ Y|x \\sim \\text{Bernoulli}(\\mu) \\] Componente sistemática \\[ g(\\mu) = g(P(Y=1\\,|\\,x)) = \\alpha + \\beta x \\] Função de ligação \\[ g(\\mu) = \\log\\left(\\frac{\\mu}{1-\\mu}\\right) \\] "],
["funcao-deviance.html", "6.8 Função Deviance", " 6.8 Função Deviance \\[ \\begin{aligned} D(y,\\hat\\mu(x)) &amp;= \\sum_{i=1}^n 2\\left[y_i\\log\\frac{y_i}{\\hat\\mu_i(x_i)} + (1-y_i)\\log\\left(\\frac{1-y_i}{1-\\hat\\mu_i(x_i)}\\right)\\right] = \\\\ &amp;= 2 D_{KL}\\left(y||\\hat\\mu(x)\\right), \\end{aligned} \\] onde \\(D_{KL}(p||q) = \\sum_i p_i\\log\\frac{p_i}{q_i}\\) é a divergência de Kullback-Leibler. Agora, veja um modelo de deep learning: Faz uma combinação linear inputs \\(x\\), adiciona um viés (bias) e depois aplica uma função de ativação não linear. No nosso caso, adiciona um parâmetro multiplicando \\(x\\) e um viés fixo, fazendo \\[ f(x) = w x + \\text{bias} \\] A função de ativação é uma sigmoide, dada por \\[ \\sigma(x) = \\frac{1}{1 + e^{-x}} \\] Notou alguma similaridade? 6.8.1 Função de custo: categorical cross-entropy \\[ \\begin{aligned} H(p, q) &amp;= H(p) + D_{KL}(p||q) \\\\ &amp;= -\\sum_x p(x)\\log(q(x)) \\end{aligned} \\] No nosso caso, isso é equivalente a uma constante mais a função deviance. Para ajustar os parâmetros, existem diversos algoritmos de otimização. Um dos mais utilizados é o de descida de gradiente estocástico. 6.8.2 Exemplot logistic &lt;- function(x) 1 / (1 + exp(-x)) n &lt;- 100000 set.seed(19910401) dados &lt;- tibble( x = runif(n, -2, 2), y = rbinom(n, 1, prob = logistic(-1 + 2 * x)) ) dados Ajustando uma regressão logística no R modelo &lt;- glm(y ~ x, data = dados, family = &#39;binomial&#39;) broom::tidy(modelo) Ajustando um deep learning com o keras library(keras) input_keras &lt;- layer_input(shape = 1, name = &quot;modelo_keras&quot;) output_keras &lt;- input_keras %&gt;% layer_dense(units = 1, name = &quot;camada_unica&quot;) %&gt;% layer_activation(&quot;sigmoid&quot;, input_shape = 1, name = &quot;link_logistic&quot;) # Constrói a nossa hipótese f(x) (da E[y] = f(x)) modelo_keras &lt;- keras_model(input_keras, output_keras) A especificação do modelo é dada por summary(modelo_keras) #&gt; ___________________________________________________________________________ #&gt; Layer (type) Output Shape Param # #&gt; =========================================================================== #&gt; modelo_keras (InputLayer) (None, 1) 0 #&gt; ___________________________________________________________________________ #&gt; camada_unica (Dense) (None, 1) 2 #&gt; ___________________________________________________________________________ #&gt; link_logistic (Activation) (None, 1) 0 #&gt; =========================================================================== #&gt; Total params: 2 #&gt; Trainable params: 2 #&gt; Non-trainable params: 0 #&gt; ___________________________________________________________________________ Agora, especificamos a função de perda e a forma de otimizar modelo_keras %&gt;% compile( loss = &#39;binary_crossentropy&#39;, optimizer = &quot;sgd&quot; ) modelo_keras %&gt;% fit(x = dados$x, y = dados$y, epochs = 3) modelo_keras %&gt;% get_layer(&quot;camada_unica&quot;) %&gt;% get_weights() #&gt; [[1]] #&gt; [,1] #&gt; [1,] 2.002628 #&gt; #&gt; [[2]] #&gt; [1] -1.020578 Algumas dúvidas que podem surgir para você nesse momento: Se é a mesma coisa, por que ele está ganhando tanta popularidade? Devo estudar deep learning ou posso continuar fazendo regressão logística? "],
["redes-neurais-convolucionais.html", "6.9 Redes neurais convolucionais", " 6.9 Redes neurais convolucionais Nosso objetivo é aprender a aplicar a operação da convolução em imagens, replicando o modelo já ajustado dos captchas. 6.9.1 O que é convolução, afinal? Convolução é uma técnica usada há muito tempo na área de visão computacional para aplicar filtros em imagens e detectar padrões. Basicamente, o que ela faz é calcular um novo valor para um pixel da imagem com base nos pixels da vizinhança. Por exemplo, você pode fazer com que o pixel \\((i,j)\\) da sua imagem seja atualizado pela soma ponderada dos valores dos pixels na vizinhança. Uma forma esperta de fazer essa soma ponderada é criando uma matriz de pesos: dessa forma, você não precisa ficar procurando os pontos da vizinhança. Para cada ponto \\((i,j)\\), você pega o subset da matriz de vizinhança, multiplica pontualmente pela matriz de pesos e soma todos os valores. Isso é exatamente o que a convolução faz. Daqui em diante, chamaremos essa matriz de pesos de kernel. Considere esse exemplo 3x3: kern_horizontal &lt;- rbind(c(-1,-1,-1), c( 0, 0, 0), c( 1, 1, 1)) kern_horizontal #&gt; [,1] [,2] [,3] #&gt; [1,] -1 -1 -1 #&gt; [2,] 0 0 0 #&gt; [3,] 1 1 1 E considere essa imagem super complexa: &quot;imgs/emoji3.png&quot; %&gt;% magick::image_read() %&gt;% plot() Na prática, essa imagem é isso aqui (tirei algumas linhas e colunas): emoji &lt;- decryptr:::load_image(&quot;imgs/emoji3.png&quot;)[,,1] round(emoji, 1)[1:10, 1:12] #&gt; [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] #&gt; [1,] 1 1 1 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 #&gt; [2,] 1 1 1 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 #&gt; [3,] 1 1 1 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 #&gt; [4,] 1 1 1 1.0 1.0 1.0 1.0 1.0 0.8 0.7 0.7 0.7 #&gt; [5,] 1 1 1 1.0 1.0 1.0 0.9 0.6 0.8 1.0 1.0 1.0 #&gt; [6,] 1 1 1 1.0 1.0 0.8 0.7 1.0 1.0 1.0 1.0 1.0 #&gt; [7,] 1 1 1 1.0 0.9 0.7 1.0 1.0 1.0 1.0 1.0 1.0 #&gt; [8,] 1 1 1 1.0 0.6 1.0 1.0 1.0 1.0 1.0 1.0 1.0 #&gt; [9,] 1 1 1 0.8 0.8 1.0 1.0 0.9 0.9 1.0 1.0 1.0 #&gt; [10,] 1 1 1 0.7 1.0 1.0 0.7 0.4 0.2 0.7 0.9 1.0 Tome por exemplo o ponto \\((i,j) = (12,16)\\). A vizinhança 3x3 em torno desse ponto é dada por emoji[12 + (-1):1, 16 + (-1):1] #&gt; [,1] [,2] [,3] #&gt; [1,] 0.9843137 0.5294118 0.7921569 #&gt; [2,] 0.9725490 0.9882353 1.0000000 #&gt; [3,] 0.9843137 1.0000000 0.9960784 A operação de convolução é feita da seguinte forma: sum(emoji[12 + (-1):1, 16 + (-1):1] * kern_horizontal) #&gt; [1] 0.6745098 Pronto, esse é o valor a ser colocado no ponto \\((i,j)\\). Fazemos isso para todos os outros pontos. Algumas dúvidas que podem rolar nesse ponto: Exercício Qual o resultado se aplicarmos a convolução no ponto (12, 12)? Qual o resultado se aplicarmos a convolução no ponto (1, 1)? Q: Mas os números não devem variar de 0 a 1? R: Não! Para visualizar a imagem, você poderia normalizar essas quantidades (por exemplo, dividindo pelo máximo). Mas quem disse que o resultado da sua operação precisa ser visualizável? O resultado pode até ser negativo. Sem problemas. Para visualização, por padrão os valores menores que zero são substituídos por zero (preto) e valores maiores que um são substituídos por um (branco). Q: Mas e no canto da imagem, o que fazemos? R: Nos cantos, você tem duas opções: 1) considerar apenas os pixels válidos, ou seja, pixels em que você consegue encaixar a matriz kernel inteira, resultando numa matriz de tamanho menor; ou 2) criar uma borda na imagem, preenchendo com zeros, para que toda a imagem fique com pixels válidos. Por isso que o keras disponibiliza as opções valid (apenas os válidos) e same (mantém a mesma dimensão). Q: E se a imagem for colorida? R: Boa pergunta! Se a imagem for colorida, você pode considerar um kernel diferente para cada cor, e depois você soma todos os valores. Mais pra frente, chamaremos as cores de canais, pois teremos muito mais do que 3 kernels. Com base nisso, montamos um algoritmo que faz a conta para todos os pixels, já criando uma borda na imagem: convolve &lt;- function(img, kern) { # monta a bordinha na imagem. A borda deve ter (tamanho kernel) / 2, # de tamanho, arredondando para baixo pad &lt;- floor(dim(kern)[1] / 2) img_pad &lt;- matrix(0, nrow = nrow(img) + 2 * pad, ncol = ncol(img) + 2 * pad) img_pad[pad + 1:nrow(img), pad + 1:ncol(img)] &lt;- img[,,1] # aplica a convolução nos pontos da imagem for (i in seq_len(nrow(img))) { for (j in seq_len(ncol(img))) { img[i, j, 1] &lt;- sum(img_pad[i + 0:(2 * pad), j + 0:(2 * pad)] * kern) } } img[,,2] &lt;- img[,,3] &lt;- img[,,1] img } Exercício Qual é o problema do código acima? Voltando para nossa imagem agora. No nosso caso, o resultado fica assim: &quot;imgs/emoji3.png&quot; %&gt;% decryptr:::load_image() %&gt;% convolve(kern_horizontal) %&gt;% magick::image_read() %&gt;% plot() Ficou um pouco assustador, não? Essa matriz não foi escolhida por acaso. Ela serve para destacar padrões horizontais da imagem. Como a primeira linha é formada -1s e a última é formada por 1s, a matriz fica com valor alto se a parte de cima do pixel for preta e a parte de baixo for branca (grande * 1 + pequeno * (-1)). A parte destacada da imagem acabou sendo os olhos (pois temos maior concentração de pixels pretos ali), além das extremidades superior e inferior do rosto. Com esse kernel aqui (vertical), a parte destacada do rosto são as extremidades dos lados: kern_vertical &lt;- rbind(c(-1, 0, 1), c(-1, 0, 1), c(-1, 0, 1)) kern_vertical #&gt; [,1] [,2] [,3] #&gt; [1,] -1 0 1 #&gt; [2,] -1 0 1 #&gt; [3,] -1 0 1 &quot;imgs/emoji3.png&quot; %&gt;% decryptr:::load_image() %&gt;% convolve(kern_vertical) %&gt;% magick::image_read() %&gt;% plot() 6.9.2 Aplicando nos captchas Não tem segredo! Basta reaplicar o que já vimos. Vou apenas introduzir uma nova função chamada add_bias(), que simplesmente adiciona uma constante numérica para a matriz. Isso pode auxiliar na visualização, pois controlamos melhor os valores que ficam dentro do intervalo [0,1]. Lá na frente você entenderá o porquê do “bias”. add_bias &lt;- function (x, b) x + b Esse é o resultado de adicionar o kernel vertical e bias de 0.6. arq &lt;- &quot;imgs/receita/captcha48ec12131bab.png&quot; op &lt;- graphics::par(mar = rep(0, 4)) arq %&gt;% decryptr:::load_image() %&gt;% convolve(kern_vertical) %&gt;% add_bias(.6) %&gt;% magick::image_read() %&gt;% plot() Agora o kernel na horizontal. Note que identificamos padrões das linhas horizontais que tentam atrapalhar a visão das letras. op &lt;- graphics::par(mar = rep(0, 4)) arq %&gt;% decryptr:::load_image() %&gt;% convolve(kern_horizontal) %&gt;% add_bias(.6) %&gt;% magick::image_read() %&gt;% plot() Colocando um após o outro, temos um resultado bem esquisito: op &lt;- graphics::par(mar = rep(0, 4)) arq %&gt;% decryptr:::load_image() %&gt;% convolve(kern_horizontal) %&gt;% convolve(kern_vertical) %&gt;% add_bias(.5) %&gt;% magick::image_read() %&gt;% plot() Também vou introduzir uma função chamada relu() aqui. ReLu significa Restricted Linear Unit e é uma função bem simples que zera tudo aquilo que é negativo e mantém tudo aquilo que é positivo. Assim, temos: relu &lt;- function(x) (x + abs(x)) / 2 relu(-1) #&gt; [1] 0 relu( 3) #&gt; [1] 3 Para visualização, essa função não serve para muita coisa, pois já fazemos a substituição de valores negativos por zero. No entanto, podemos fazer combos com a aplicação de várias convoluções. O resultado dos combos não seria possível somente com somas e multiplicações. Na prática, isso significa que com a aplicação de convoluções, bias e ReLu, podemos montar operações não lineares para extrair componentes da imagem. Olhe o exemplo abaixo. Parece que consegui identificar bem as coisas que são inúteis na imagem. op &lt;- graphics::par(mar = rep(0, 4)) arq %&gt;% decryptr:::load_image() %&gt;% # primeira convolucao convolve(kern_horizontal) %&gt;% add_bias(-.25) %&gt;% relu() %&gt;% # segunda convolucao convolve(kern_vertical) %&gt;% add_bias(.1) %&gt;% magick::image_read() %&gt;% plot() Isso tudo nos leva a pensar: será que eu consigo pensar em kernels que me ajudem a identificar as letras de uma forma razoável? 6.9.3 E se pudermos usar kernels treinados? A revolução da convolução aparece quando conseguimos obter kernels úteis por métodos estatísticos. Podemos pensar na matriz abaixo \\[ W = \\left[\\begin{array}{ccccc} w_{11} &amp; w_{12} &amp; w_{13} &amp; w_{14} &amp; w_{15} \\\\ w_{21} &amp; w_{22} &amp; w_{23} &amp; w_{24} &amp; w_{25} \\\\ w_{31} &amp; w_{32} &amp; w_{33} &amp; w_{34} &amp; w_{35} \\\\ w_{41} &amp; w_{42} &amp; w_{43} &amp; w_{44} &amp; w_{45} \\\\ w_{51} &amp; w_{52} &amp; w_{53} &amp; w_{54} &amp; w_{55} \\end{array}\\right] \\] e tentar encontrar os valores de \\(W\\) que minimizem alguma função de interesse. Podemos pensar que esses são os \\(\\beta\\)’s de uma regressão logística, e queremos encontrar os valores que minimizam uma Loss ou maximizam uma verossimilhança. Nós também podemos fazer vários \\(W\\) como esse, sendo que cada um extrai alguma coisa de importante da imagem. Nosso super modelo de magia negra nada mais é do que isso: a aplicação consecutiva de convolve(), add_bias() e relu(), mas com pesos escolhidos a dedo (ou por um moedor de carne super-poderoso como o keras). Agora podemos ver nosso modelo atual da Receita Federal: m &lt;- decryptr::load_model(&quot;rfb&quot;) m$model #&gt; Model #&gt; ___________________________________________________________________________ #&gt; Layer (type) Output Shape Param # #&gt; =========================================================================== #&gt; conv2d_4 (Conv2D) (None, 50, 180, 12) 312 #&gt; ___________________________________________________________________________ #&gt; max_pooling2d_4 (MaxPooling2D) (None, 25, 90, 12) 0 #&gt; ___________________________________________________________________________ #&gt; conv2d_5 (Conv2D) (None, 25, 90, 48) 14448 #&gt; ___________________________________________________________________________ #&gt; max_pooling2d_5 (MaxPooling2D) (None, 12, 45, 48) 0 #&gt; ___________________________________________________________________________ #&gt; conv2d_6 (Conv2D) (None, 12, 45, 96) 115296 #&gt; ___________________________________________________________________________ #&gt; max_pooling2d_6 (MaxPooling2D) (None, 6, 22, 96) 0 #&gt; ___________________________________________________________________________ #&gt; flatten_2 (Flatten) (None, 12672) 0 #&gt; ___________________________________________________________________________ #&gt; dense_3 (Dense) (None, 32) 405536 #&gt; ___________________________________________________________________________ #&gt; dropout_2 (Dropout) (None, 32) 0 #&gt; ___________________________________________________________________________ #&gt; dense_4 (Dense) (None, 210) 6930 #&gt; ___________________________________________________________________________ #&gt; reshape_2 (Reshape) (None, 6, 35) 0 #&gt; ___________________________________________________________________________ #&gt; activation_2 (Activation) (None, 6, 35) 0 #&gt; =========================================================================== #&gt; Total params: 542,522 #&gt; Trainable params: 542,522 #&gt; Non-trainable params: 0 #&gt; ___________________________________________________________________________ O modelo aplica convolução 3 vezes consecutivas e faz algumas contas que não entendemos. Explico agora: conv2d_: são as convoluções. As aplicações de add_bias() e relu() estão escondidas aí dentro. max_pooling2d_: serve para simplificar a imagem. Isso ajuda a fazer computações mais rápido e ajuda a pegar mais relações entre partes da imagem, sem precisar mudar o tamanho dos kernels. dropout_: é utilizado para regularização. Serve para evitar que seu modelo quebre apenas o captcha que você tem na base, e não novos captchas que chegam. Na prática, o dropout joga fora uma parte dos \\(W\\) obtidos. Se você consegue prever coisas bem sem esses \\(W\\), isso significa que eles não são tão úteis assim. flatten_ e reshape_: não fazem nada demais, só reorganizam os parâmetros de matriz para um vetor ou de vetor para matriz. Isso é útil pois i) depois de aplicar os kernels, nós misturamos todos os parâmetros resultantes e ii) no final, precisamos prever 6 letras, então precisamos deixar as probabilidades numa matriz. dense_: são camadas de redes neurais comuns como as que vimos antes, próximas da regressão logística. NÃO NOS ABANDONE AQUI!!! Se você não estiver entendendo direito, saiba apenas que a execução de um modelo de deep learning envolve somente Pegar o input (imagem). Multiplicar (convoluir) por alguns pesos \\(W\\). Adicionar um viés (ou bias, ou intercepto) \\(b\\). Aplicar uma função não linear, por exemplo ReLu. Voltar para 2 várias vezes (o deep vem daí). Pegar os pesos finais e normalizar (usando, por exemplo, softmax) para obter probabilidades dos resultados. No nosso caso, repetimos o passo 2 três vezes, aplicando três convoluções seguidas. 6.9.4 Primeira convolução Para obter os valores de kernels ajustados pelo modelo, podemos usar a função get_weights() do keras. Nessa primeira parte, utilizamos 12 kernels 5x5. w &lt;- keras::get_weights(m$model$layers[[1]])[[1]] w_list &lt;- purrr::map(seq_len(dim(w)[4]), ~w[,,1,.x]) bias &lt;- keras::get_weights(m$model$layers[[1]])[[2]] w_list[[1]] #&gt; [,1] [,2] [,3] [,4] [,5] #&gt; [1,] -0.00889198 0.04569587 0.11906113 0.08591988 -0.09028889 #&gt; [2,] -0.05898214 0.20692091 -0.13479255 -0.15641896 -0.10511240 #&gt; [3,] 0.02517573 -0.63352644 -3.81658459 -4.39883375 -1.05918467 #&gt; [4,] -0.22003661 -1.80763698 -3.13373542 -1.73096466 -0.01640752 #&gt; [5,] -0.02915078 -0.11879896 -0.07475707 0.06014036 0.15733875 Os doze valores de bias estimados pelo modelo (um para cada matriz) são dados por round(bias, 3) #&gt; [1] 0.150 0.013 0.181 -0.275 0.179 0.040 -0.128 -0.036 0.030 0.042 #&gt; [11] 0.201 0.043 Para cada um dos doze kernels, calculamos uma matriz convoluída. Esses os resultados que o modelo entende serem úteis para prever o captcha. O código abaixo aplica convolve(), add_bias() e relu() para todos os kernels. Para isso usamos o purrr. Se você não entende purrr, leia este maravilhoso post do Caio Lente. conv1 &lt;- purrr::map2(w_list, bias, ~{ arq %&gt;% decryptr:::load_image() %&gt;% convolve(.x) %&gt;% add_bias(.y) %&gt;% relu() }) E como será que ficam essas imagens? Abaixo, temos o resultado da aplicação dos doze kernels. A maioria parece estar extraindo partes das letras. A sétima (posição (2,3)) parece estar pegando o ruído e a quarta parece guardar a imagem original. conv1_img &lt;- purrr::map(conv1, magick::image_read) par(mfrow = c(3, 4), mar = c(.1,.1,.1,.1)) purrr::walk(conv1_img, plot) O gif animado abaixo mostra a aplicação do oitavo kernel da nossa lista. Com esse kernel dá pra pegar bem o padrão das letras, não é? convolve_image &lt;- function(img, kern) { pad &lt;- floor(dim(kern)[1] / 2) img_pad &lt;- matrix(0, nrow = nrow(img) + 2 * pad, ncol = ncol(img) + 2 * pad) img_pad[pad + 1:nrow(img), pad + 1:ncol(img)] &lt;- img[,,1] d &lt;- tibble::tibble(i = 0, j = 0, img = list()) for (i in seq_len(nrow(img))) { for(j in seq_len(ncol(img))) { img[i,j,1] &lt;- sum(img_pad[i + 0:(2 * pad), j + 0:(2 * pad)] * kern) } img[,,2] &lt;- img[,,3] &lt;- img[,,1] d &lt;- tibble::add_row(d, i = i, j = j, img = list(magick::image_read(img) %&gt;% magick::image_scale(&quot;300%&quot;))) } d } arq %&gt;% decryptr:::load_image() %&gt;% convolve_image(w_list[[8]]) %&gt;% with(img) %&gt;% magick::image_join() %&gt;% magick::image_animate(fps = 100) %&gt;% magick::image_write(&quot;imgs/captcha_conv.gif&quot;) magick::image_read(&quot;imgs/captcha_conv.gif&quot;) No próximo nível, vamos convoluir mais 48 kernels. Essa operação será feita com todos os doze filtros atuais, ou seja, é uma contaiada que não acaba mais. Para simplificar as contas e para permitir a obtenção de padrões diferentes, faz sentido simplificar a imagem. Para isso, usamos o max pooling. 6.9.4.1 Aplicando max pooling O max pooling simplesmente pega o pixel de maior valor dentro de uma janela. No caso, estamos usando uma janela 2x2 e aplicamos ela igualzinho convolução, só que ao invés de pegar a soma ponderada dos pixels, pegamos o pixel máximo. Outra diferença é que ao invés de andar o pixel de 1 em 1, andamos de 2 em 2. Assim cada janelinha é considerada apenas uma vez (esse é o conceito de strides, que não vamos discutir aqui). Montei esse algoritmo que faz max pooling: max_pool &lt;- function(img) { # monta a matriz com metade da resolução x_new &lt;- matrix(0.0, nrow = floor(nrow(img) / 2), ncol = floor(ncol(img) / 2)) # adiciona uma bordinha para o caso da matriz ter um número ímpar de pixels # por exemplo, se ela é 51x181, daria bug se não adicionar a bordinha img &lt;- cbind(rbind(img[,,1], 0), 0) # percorre a matrix pegando o máximo das janelinhas for (i in 1:nrow(x_new)) { for (j in 1:ncol(x_new)) { x_new[i, j] &lt;- max(img[i * 2 - 1 + 0:1, j * 2 - 1 + 0:1]) } } array(x_new, c(dim(x_new), 3)) } A aplicação da primeira convolução com max pooling é feita igual anteriormente: result_conv1 &lt;- purrr::map2(w_list, bias, ~{ arq %&gt;% decryptr:::load_image() %&gt;% convolve(.x) %&gt;% add_bias(.y) %&gt;% relu() %&gt;% max_pool() }) No final, temos essas imagens com resolução 25x90 (as originais são 50x180). op &lt;- graphics::par(mar = rep(0, 4)) par(mfrow = c(3, 4), mar = c(.1,.1,.1,.1)) result_conv1 %&gt;% purrr::walk(~plot(magick::image_read(.x))) Ficou bem parecido com o anterior! Ao final da convolução, é como se tivéssemos uma nova imagem, menor e alterada, mas com 12 cores. Como não faz muito sentido pensar em 12 cores primárias, vamos chamá-las de canais. 6.9.5 Segunda convolução Os parâmetros da segunda convolução são obtidos novamente pelo keras. Sugiro que você dê uma olhada nesses índices para entender o que exatamente estamos pegando. w2 &lt;- keras::get_weights(m$model$layers[[3]])[[1]] bias2 &lt;- keras::get_weights(m$model$layers[[3]])[[2]] dim(w2) #&gt; [1] 5 5 12 48 Agora temos 12 * 48 kernels 5x5 a serem aplicados. Precisamos seguir essas operações: Para cada uma das 48 matrizes: Faça a convolução das 12 matrizes obtidos na convolução anterior pelos 12 kernels atuais e some os valores obtidos. Adicione o bias. Faça a ativação com ReLu. Aplique o max pooling. Logo, temos 2 laços. O código para fazer isso fica assim: result_conv2 &lt;- purrr::map(1:dim(w2)[4], ~{ kern &lt;- w2[,,,.x] %&gt;% plyr::alply(3, identity) %&gt;% purrr::map(as.matrix) actual_bias &lt;- bias2[[.x]] purrr::map2(result_conv1, kern, convolve) %&gt;% purrr::reduce(magrittr::add) %&gt;% add_bias(actual_bias) %&gt;% relu() %&gt;% max_pool() }) Plotamos os 48 resultados abaixo. Alguns resultados foram completamente zerados (eles devem ser úteis em outros captchas mais esquisitos), enquanto os demais pegam pedaços da imagem anterior que mal lembram o captcha original. A imagem da posição (4,1) é uma das únicas que mostra o captcha claramente. Isso mostra uma coisa comum do deep learning: quanto mais profundo vamos, menos entendemos o que de fato o modelo está fazendo. Recomendo fortemente a leitura desse blog do distill, que discute o assunto detalhadamente op &lt;- graphics::par(mar = rep(0, 4)) par(mfrow = c(8, 6), mar = c(.1,.1,.1,.1)) purrr::walk(result_conv2, ~plot(magick::image_read(.x))) Agora temos 48 canais de uma imagem com dimensões 12x45. Vamos em frente. 6.9.6 Terceira convolução A terceira convolução é feita de forma idêntica à segunda. A única diferença é que teremos no final 96 canais, pois estamos ajustando essa quantidade de kernels para cada canal. w3 &lt;- keras::get_weights(m$model$layers[[5]])[[1]] bias3 &lt;- keras::get_weights(m$model$layers[[5]])[[2]] dim(w3) #&gt; [1] 5 5 48 96 Revisando o algoritmo: result_conv3 &lt;- purrr::map(1:dim(w3)[4], ~{ kern &lt;- w3[,,,.x] %&gt;% plyr::alply(3, identity) %&gt;% purrr::map(as.matrix) actual_bias &lt;- bias3[[.x]] purrr::map2(result_conv2, kern, convolve) %&gt;% purrr::reduce(magrittr::add) %&gt;% add_bias(actual_bias) %&gt;% relu() %&gt;% max_pool() }) Plotando os resultados, temos par(mfrow = c(12, 8), mar = c(.1,.1,.1,.1)) purrr::walk(result_conv3, ~plot(magick::image_read(.x))) No final, ficamos com 96 imagens com resolução 6x22 cada. Várias imagens ficaram zeradas e as que não ficaram parecem apenas feixes de luz no meio do breu. Pode ser que a posição dessas luzes tenha a ver com a posição de pedaços importantes do captcha original, que por sua vez seriam importantes para determinar o valor do captcha. 6.9.6.1 Visualizando na imagem original Aqui fiz um esforço para tentar entender de qual parte da imagem original esses resultados estão pegando informações. Para isso, re-escalei essas imagens de resolução mais baixa na última convolução para o tamanho original do captcha (50x180) e depois multipliquei os valores das matrizes pelos valores da imagem original. O resultado foi esse gif. Cada imagem é um dos canais obtidos. op &lt;- graphics::par(mar = rep(0, 4)) mat_captcha &lt;- 1 - decryptr:::load_image(arq)[,,1] imagens_alteradas &lt;- purrr::imap(result_conv3, ~{ .x %&gt;% magick::image_read() %&gt;% magick::image_scale(&quot;180x!50&quot;) %&gt;% as.raster() %&gt;% { apply(., 2, function(x) col2rgb(x)[1,]) / 255 } %&gt;% magrittr::multiply_by(mat_captcha) %&gt;% array(dim = c(dim(.), 3)) %&gt;% magick::image_read() %&gt;% magick::image_scale(&quot;400%&quot;) %&gt;% magick::image_annotate(as.character(.y), color = &quot;white&quot;, size = 40) }) %&gt;% magick::image_join() %&gt;% magick::image_animate(fps = 1) imagens_alteradas Parece que os filtros são capazes de pegar as curvas que as letras fazem no captcha. Mas não tenho opinião formada sobre isso. 6.9.7 Passos finais Para acabar a predição do captcha, nós pegamos os resultados das imagens anteriores e juntamos todos os pixels num vetorzão que junta tudo. Em estatistiquês, esse vetor nada mais é do que uma linha de um data.frame, que podemos usar numa regressão logística, por exemplo. Ou seja, essas convolucionais funcionam como um grande gerador automático de features importantes para prever os resultados do captcha. A vantagem é que essas features são obtidas de forma automática e são otimizadas dentro do processo de estimação. Por essas e outras que deep learning é realmente sensacional! Como já estamos no framework do keras, acabamos fazendo tudo lá dentro. Após jogar tudo no vetorzão, aplicamos mais dois layers de redes neurais comuns, que funcionam como a regressão logística. O único detalhe sensível é que, como estamos prevendo 6 letras ao mesmo tempo, precisamos novamente transformar esse vetor em uma matriz 35x6, sendo 35 o total de letras possíveis por posição e 6 a quantidade de posições. Abaixo, montei uma tabelinha com as probabilidades de cada letra nas posições correspondentes. Substituí valores muito pequenos por . para ver melhor. captcha &lt;- read_captcha(arq) X &lt;- array(dim = c(1, nrow(captcha[[1]]$x), ncol(captcha[[1]]$x), 1)) X[1, , , ] &lt;- captcha[[1]]$x res2 &lt;- keras::predict_proba(m$model, X) probabilidades &lt;- res2[1,,] %&gt;% tibble::as_tibble() %&gt;% purrr::set_names(m$labs) %&gt;% tidyr::gather(letra, prob) %&gt;% dplyr::group_by(letra) %&gt;% dplyr::mutate(pos = 1:n()) %&gt;% dplyr::ungroup() %&gt;% dplyr::mutate(prob = dplyr::if_else(prob &lt; 5e-5, &quot;.&quot;, as.character(round(prob, 6))) ) %&gt;% tidyr::spread(pos, prob, sep = &quot;&quot;) knitr::kable(probabilidades) letra pos1 pos2 pos3 pos4 pos5 pos6 1 . . . . . . 2 . . . . . . 3 . 0.999983 . . . . 4 . . . . . . 5 . . . . . . 6 . . . . . . 7 . . . . . . 8 . . . . . . 9 . . . . . . a . . . . . . b . . . . . . c . . . . . . d . . . . . . e . . . . . . f . . . . . . g 1 . . . . 0.999996 h . . . . . . i . . . . . . j . . . . 1 . k . . 0.999987 . . . l . . . . . . m . . . . . . n . . . . . . o . . . . . . p . . . . . . q . . . . . . r . . . . . . s . . . . . . t . . . . . . u . . . . . . v . . . 0.994037 . . w . . . . . . x . . . 0.000151 . . y . . . 0.005796 . . z . . . . . . Ficamos então com “g” na primeira posição, “3” na segunda posição, “k” na terceira posição, “v” na quarta posição, “j” na quinta posição e “g” na sexta posição. Ou seja, “g3kvjg”. Vamos ver a imagem novamente: arq %&gt;% read_captcha() %&gt;% plot() Parece que funcionou! 6.9.8 Wrap-up Resumindo: Convoluções são somas ponderadas dos valores da vizinhança de um pixel. Esses pesos são dados por uma matriz chamada kernel. Aplicar redes neurais convolucionais consiste em i) aplicar convolução; ii) adicionar um bias; iii) aplicar uma função não linear (geralmente ReLu). max pooling serve para simplificar a resolução da imagem. Na prática, aplicamos vários kernels. O número de kernels de uma convolucional igual ao número de canais da operação anterior (input), multiplicado pelo número de canais que queremos de output. Para a convolução inicial, os canais são as cores: partimos de 1 canal se a imagem for preto e branco ou 3 canais se for colorida. No nosso caso, aplicamos três convolucionais com kernels 5x5, sendo 1*12 no primeiro nível, 12*48 no segundo nível e 48*96 no terceiro nível. Depois, pegamos as imagens resultantes e aplicamos o flatten, para trabalhar com esses números como se fossem a matriz X de uma regressão logística usual. Como vimos, é possível implementar todas essas operações na mão sem muita dificuldade. "],
["wrap-up-do-curso.html", "6.10 Wrap-up do curso", " 6.10 Wrap-up do curso Nossa jornada foi longa e cheia de aprendizados. Resumidamente, o que fizemos foi Introdução à jurimetria estudos prospectivos e retrospectivos exemplos: câmaras e especialização Importação de dados com o esaj e o dje Tidyverse stringr, lubridate, forcats dplyr, tidyr, janitor purrr Modelos Análise de sobrevivência Captchas "],
["references.html", "References", " References "]
]
